{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a964dec",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; background-color:white;\">\n",
    "<tr>\n",
    "    <td style=\"width:33%; text-align:center;\">\n",
    "        <img src=\"logo_universite.png\" style=\"width:100px; height:150px; display:block; margin:auto; margin-bottom:20px;\"/><br>\n",
    "        Réalisé par :<br>\n",
    "        Marouane Sennah<br>\n",
    "        Sofia Fennich<br>\n",
    "        Romane Hiba<br>\n",
    "        Zouaoui Basma<br>\n",
    "        Sidki Imane<br>\n",
    "        Hiba Khouzai\n",
    "    </td>\n",
    "    <td style=\"width:34%; text-align:center; vertical-align:middle;\">\n",
    "        <h2 style=\"font-weight:bold; margin-bottom:20px;\">TP1<br>Introduction aux réseaux de neurones</h2>\n",
    "    </td>\n",
    "    <td style=\"width:33%; text-align:center;\">\n",
    "        <img src=\"ensa_logo.png\" style=\"width:200px; height:190px; display:block; margin:auto; margin-bottom:20px;\"/><br>\n",
    "        Sous la supervision de :<br>\n",
    "        Monsieur Khalfi\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1e473",
   "metadata": {},
   "source": [
    "# Partie 1 – Formalisation mathématique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c360e",
   "metadata": {},
   "source": [
    "## 1.1 Jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c040e8",
   "metadata": {},
   "source": [
    "<strong>1.1 Ensemble d'apprentissage (train) :</strong>\n",
    "\n",
    "Utilisé pour entraîner le modèle.\n",
    "Le modèle \"apprend\" à partir de ces données en ajustant ses paramètres pour minimiser l'erreur entre les prédictions et les vraies valeurs.\n",
    "C'est sur cet ensemble que l'algorithme d'apprentissage tente d'optimiser la fonction de coût."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0819b",
   "metadata": {},
   "source": [
    "<strong>1.2 Ensemble de validation (val) :</strong>\n",
    "\n",
    "Utilisé pour évaluer la performance du modèle pendant la phase d'entraînement et aider à régler les hyperparamètres (par exemple, le taux d'apprentissage, le nombre de couches cachées, etc.).\n",
    "Permet de détecter le surajustement (ou overfitting) : Si le modèle a une bonne performance sur l'ensemble d'entraînement mais une mauvaise performance sur l'ensemble de validation, cela indique généralement qu'il est surajusté aux données d'entraînement.\n",
    "Cet ensemble aide à faire un choix sur la meilleure version ou configuration du modèle sans toucher à l'ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701f45f",
   "metadata": {},
   "source": [
    "<strong>1.3 Ensemble de test (test) :</strong>\n",
    "\n",
    "Utilisé pour évaluer la performance finale du modèle après l'entraînement.\n",
    "Donne une estimation de la performance du modèle sur de nouvelles données, c'est-à-dire des données qu'il n'a jamais vues auparavant.\n",
    "L'ensemble de test doit être mis de côté et utilisé uniquement pour l'évaluation finale afin de garantir une estimation honnête de la performance du modèle dans des conditions réelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12478c4c",
   "metadata": {},
   "source": [
    "<strong>2. Quelle est l’influence du nombre N d’exemples ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b9c62",
   "metadata": {},
   "source": [
    "2.1 Capacité d'apprentissage:\n",
    "\n",
    "<strong>Plus de données:</strong> Avec un plus grand N, il est plus probable que le modèle généralise bien pour des données inédites. Avoir plus d'exemples réduit la variance des prédictions du modèle et diminue la probabilité d'overfitting (surajustement).\n",
    "\n",
    "<strong>Moins de données:</strong> Avec un petit N, le modèle risque de surajuster aux données d'entraînement. Cela signifie qu'il peut obtenir une performance exceptionnelle sur l'ensemble d'entraînement mais une mauvaise performance sur l'ensemble de test ou de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def63fc2",
   "metadata": {},
   "source": [
    "## 1.2 Architecture du reseau (phase forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224bc6a",
   "metadata": {},
   "source": [
    "<strong>3. Pourquoi est-il important d’ajouter des fonctions d’activation entre des transformations lineaires ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d6fb8",
   "metadata": {},
   "source": [
    "Pour introduire de la non-linéarité, permettant au réseau de modéliser des relations plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb1043",
   "metadata": {},
   "source": [
    "<strong>4. Quelles sont les tailles nx, nh, ny sur la figure 1 ? En pratique, comment ces tailles sont-elles choisies ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5e0b2",
   "metadata": {},
   "source": [
    "<img src=\"rn.png\" alt=\"Description de l'image\" style=\"width:500px; margin: 0 auto; display:block;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f355a",
   "metadata": {},
   "source": [
    "nx = 2  (2 neurones d'entrée), nh = 4 (4 neurones dans la couche cachée), ny = 2 (2 neurones de sortie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5c03e",
   "metadata": {},
   "source": [
    "<strong>5. Que representent les vecteurs yˆ et y ? Quelle est la difference entre ces deux quantites ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f5c41",
   "metadata": {},
   "source": [
    "y^ représente les prédictions du réseau, tandis que  y est le vrai label ou la véritable sortie. La différence est que y^  st une estimation alors que y est la vérité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f02277",
   "metadata": {},
   "source": [
    "<strong>6. Pourquoi utiliser une fonction SoftMax en sortie ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90120f6c",
   "metadata": {},
   "source": [
    "SoftMax convertit les scores de sortie en probabilités, ce qui est utile pour les tâches de classification où l'on veut identifier la classe la plus probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01d806",
   "metadata": {},
   "source": [
    "<strong>7. Ecrire les equations mathematiques permettant d’effectuer la passe forward du reseau de neurones,\n",
    "c’est-a-dire permettant de produire successivement h˜, h, y˜ et yˆ a partir de x.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c3aa5",
   "metadata": {},
   "source": [
    "h = Wh * x + bh\n",
    "\n",
    "h^ = tanh(h)\n",
    "\n",
    "y^ = Wy * h^ + by \n",
    "\n",
    "y^ = SoftMaw(y^)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bbafa",
   "metadata": {},
   "source": [
    "<img src=\"softMax.png\" alt=\"Description de l'image\" style=\"width:500px; margin: 0 auto; display:block;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4efcc6",
   "metadata": {},
   "source": [
    "## 1.3 Fonction de cout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d698bb",
   "metadata": {},
   "source": [
    "<img src=\"loss.png\" alt=\"Description de l'image\" style=\"width:500px; margin: 0 auto; display:block;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab005d",
   "metadata": {},
   "source": [
    "Entropie Croisée (Cross-Entropy)\n",
    "L'entropie croisée est une métrique couramment utilisée pour évaluer à quel point les distributions de probabilité prédites pour un modèle de classification correspondent à la distribution des vraies étiquettes.\n",
    "\n",
    "Définition Mathématique:\n",
    "Si y est la vraie distribution et y^ est la distribution prédite, l'entropie croisée ℓ entre ces deux distributions pour un exemple donné est définie comme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8709e",
   "metadata": {},
   "source": [
    "<img src=\"corss_entropy.png\" alt=\"Description de l'image\" style=\"width:500px; margin: 0 auto; display:block;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38ca16",
   "metadata": {},
   "source": [
    "<strong>8. Pendant l’apprentissage, on cherche à minimiser la fonction de coût. Pour l’entropie croisée et l’erreur quadratique, comment les y i doivent-ils varier pour faire diminuer la loss?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7371c",
   "metadata": {},
   "source": [
    "<strong>Pour l'entropie croisée:</strong>\n",
    "<ul>\n",
    "    <li> Lorsque l'on entraîne un modèle, nous souhaitons que nos prédictions y^i ​ se rapprochent des vraies valeurs yi. Donc, pour minimiser l'entropie croisée, y^i devrait s'approcher de yi pour chaque classe i. Si yi est 1 pour une certaine classe, y^i devrait tendre vers 1; si yi est 0,  y^i devrait tendre vers 0.</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Pour l'erreur quadratique:</strong>\n",
    "<ul>\n",
    "    <li> Semblable à l'entropie croisée, pour minimiser l'erreur quadratique, la différence entre les valeurs prédites y^i et les vraies valeurs yi devrait être la plus faible possible. Cela signifie que y^i devrait être aussi proche que possible de yi.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234973d",
   "metadata": {},
   "source": [
    "<strong>9. En quoi ces fonctions sont-elles plus adaptées aux problèmes de classification ou de régression?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3ff71",
   "metadata": {},
   "source": [
    "<strong>Entropie croisée (Cross-Entropy):</strong>\n",
    "    <li>Elle est principalement utilisée pour les problèmes de classification.</li>\n",
    "    <li>L'entropie croisée pénalise fortement lorsque le modèle prédit une probabilité faible pour la vraie classe. Elle est donc idéale pour des situations où nous avons des étiquettes catégorielles comme 0 ou 1 (classification binaire) ou pour des classifications multi-classes.</li>\n",
    "    <li>Par exemple, dans la classification binaire, si la vraie étiquette est 1, mais que le modèle prédit une probabilité très faible pour cette classe, l'entropie croisée sera élevée.</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Erreur quadratique (Mean Squared Error, MSE):</strong>\n",
    "\n",
    "<ul>\n",
    "    <li>Elle est principalement utilisée pour les problèmes de régression.</li>\n",
    "    <li>Dans les problèmes de régression, l'objectif est de prédire une valeur continue plutôt qu'une étiquette catégorielle. L'erreur quadratique mesure la différence au carré entre les valeurs prédites et les vraies valeurs, ce qui la rend appropriée pour évaluer à quel point le modèle est éloigné de la vraie valeur.</li>\n",
    "<li>De plus, comme elle pénalise fortement les grandes erreurs (à cause du carré), elle est efficace pour s'assurer que le modèle ne fait pas d'erreurs trop importantes dans ses prédictions.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74924da6",
   "metadata": {},
   "source": [
    "<strong>10. Quels semblent etre les avantages et inconvenients des diverses variantes de descente de gradient\n",
    "entre les versions classique, stochastique sur mini-batch et stochastique online ? Laquelle semble la\n",
    "plus raisonnable à utiliser dans le cas général ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f4dad",
   "metadata": {},
   "source": [
    "<strong>10.1 Descente de gradient classique (batch gradient descent):</strong>\n",
    "<ul>\n",
    "    <li>\n",
    "    Avantages:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Convergence stable vers le minimum global pour les fonctions de coût convexes et le minimum local pour les fonctions de coût non convexes.\n",
    "            </li>\n",
    "            <li>\n",
    "            Facile à comprendre et à mettre en œuvre.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    Inconvénients:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Très lent sur les grands ensembles de données car il nécessite le calcul du gradient sur l'intégralité du dataset avant chaque mise à jour.\n",
    "            </li>\n",
    "            <li>\n",
    "            Nécessite beaucoup de mémoire si le dataset est volumineux.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut rester bloqué dans des minima locaux en cas de problèmes non convexes.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd15619",
   "metadata": {},
   "source": [
    "<strong>10.2 Descente de gradient stochastique (stochastic gradient descent - SGD):</strong>\n",
    "<ul>\n",
    "    <li>\n",
    "    Avantages:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Plus rapide que la descente de gradient classique, car elle actualise les poids après chaque exemple d'entraînement.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut aider à éviter les minima locaux grâce à la nature plus \"bruitée\" des mises à jour de gradient.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    Inconvénients:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Les mises à jour du gradient peuvent être très variables, rendant la convergence vers le minimum plus erratique et potentiellement plus longue.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut nécessiter une sélection judicieuse du taux d'apprentissage pour garantir la convergence.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c2169",
   "metadata": {},
   "source": [
    "<strong>10.3 Descente de gradient stochastique sur mini-batch (mini-batch SGD):</strong>\n",
    "<ul>\n",
    "    <li>\n",
    "    Avantages:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Offre un compromis entre l'efficacité de la mémoire et la rapidité de la convergence, en calculant les gradients sur de petits lots d'exemples.\n",
    "            </li>\n",
    "            <li>\n",
    "            Moins de variance dans les mises à jour du gradient par rapport à SGD, ce qui peut conduire à une convergence plus stable.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut bénéficier de l'accélération matérielle (par exemple, GPUs) grâce au parallélisme des opérations sur les lots.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    Inconvénients:\n",
    "        <ul>\n",
    "            <li>\n",
    "            Nécessite de choisir la taille du mini-batch, qui peut influencer la qualité de la convergence.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut être sensible à l'ordre des données, donc un mélange des données est souvent nécessaire.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24932b",
   "metadata": {},
   "source": [
    "<strong>10.4 Descente de gradient stochastique online (online SGD):</strong>\n",
    "<ul>\n",
    "    <li>\n",
    "    Avantages:\n",
    "        <ul>\n",
    "            <li>\n",
    "           Idéal pour les situations où les données arrivent de manière séquentielle (flux continu), comme dans l'apprentissage en ligne.\n",
    "            </li>\n",
    "            <li>\n",
    "            Peut s'adapter rapidement aux changements dans la distribution des données.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "    Inconvénients:\n",
    "        <ul>\n",
    "            <li>\n",
    "Peut être influencé par des données aberrantes plus que les autres méthodes, étant donné que chaque mise à jour est effectuée sur une seule observation à la fois.            </li>\n",
    "            <li>\n",
    "Peut requérir une mise à jour constante du taux d'apprentissage pour s'assurer de la convergence.            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecef7fe",
   "metadata": {},
   "source": [
    "En général, la descente de gradient stochastique sur mini-batch est souvent préférée dans la pratique car elle offre un bon équilibre entre la rapidité de calcul, l'efficacité de la mémoire et la convergence. Elle tire parti des avantages du traitement par lots pour optimiser l'utilisation du matériel tout en conservant suffisamment de stochastique pour éviter les minima locaux et accélérer la convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce985bdc",
   "metadata": {},
   "source": [
    "<strong>11. Quelle est l’influence du learning rate η sur l’apprentissage ? </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5b526",
   "metadata": {},
   "source": [
    "η est un hyperparamètre critique dans le processus d'entraînement des réseaux de neurones artificiels. Il détermine l'ampleur des ajustements apportés aux poids du réseau à chaque étape de la descente de gradient.<br><br>\n",
    "L'influence du learning rate sur l'apprentissage :\n",
    "<ol>\n",
    "    <li><strong>Learning rate trop élevé :</strong> Si le learning rate est trop élevé, les poids peuvent être ajustés de manière trop radicale, ce qui peut conduire le réseau à se comporter de façon instable. Les poids oscillent autour des valeurs optimales sans jamais les trouver, ou dans le pire des cas, l'erreur peut même augmenter de manière exponentielle, menant à la divergence du processus d'apprentissage.</li>\n",
    "    <li><strong>Learning rate trop faible :</strong> À l'inverse, si le learning rate est trop faible, le processus d'apprentissage peut devenir très lent, car les poids sont ajustés par de très petits incrémentiels. Cela peut entraîner un temps d'entraînement excessivement long et dans certains cas, le risque de rester bloqué dans des minima locaux au lieu de trouver le minimum global de la fonction de coût.</li>\n",
    "    <li><strong>Learning rate idéal :</strong> Un learning rate idéal permet au réseau de converger rapidement vers le minimum de la fonction de coût sans oscillations excessives ni divergence. Cependant, trouver ce taux optimal peut être difficile et nécessite souvent plusieurs essais et ajustements ou l'emploi de méthodes d'ajustement du learning rate pendant l'entraînement.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5bc2b",
   "metadata": {},
   "source": [
    "<strong>12. Comparer la complexité (en fonction du nombre de couches du reseau) du calcul des gradients de\n",
    "la loss par rapport aux paramétres, en utilisant l’approche naıve et l’algorithme de backprop</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af109b40",
   "metadata": {},
   "source": [
    "La différence  entre une approche naïve et l'algorithme de backpropagation :\n",
    "\n",
    "<ul><li><strong>Approche naive:</strong> Dans une approche naive de calcul des gradients, nous calculerions le gradient de la fonction de coût (loss) pour chaque poids sans tirer parti des calculs précédemment effectués. Cela signifie que pour chaque poids, nous considérons toutes les autres variables comme constantes et calculez l'impact de ce poids unique sur la fonction de coût. C'est une approche directe, mais incroyablement inefficace, car elle ne réutilise pas les informations calculées qui sont communes à plusieurs poids, et cela se traduirait par une énorme quantité de calculs redondants, surtout dans les réseaux avec de nombreuses couches et de nombreux neurones.</li>\n",
    "    <li><strong>Algorithme de backpropagation:</strong> En contraste, l'algorithme de backpropagation est une méthode plus sophistiquée qui utilise le théorème de la chaîne pour calculer les dérivées partielles de la fonction de coût par rapport à chaque poids de manière systématique et efficiente. nous commençons par la dernière couche (la sortie) et nous calculons les gradients couche par couche en remontant vers l'entrée, en réutilisant des calculs à chaque étape. Cette méthode est beaucoup plus rapide car elle élimine les calculs redondants.</li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "La complexité:\n",
    "<ul>\n",
    "    <li><strong>Approche naive :</strong> Dans l'approche naive, pour calculer le gradient de la loss par rapport à tous les paramètres, nous pourrions envisager de calculer la dérivée de la fonction de loss envers chaque paramètre indépendamment, sans tenir compte des calculs précédents qui pourraient être réutilisés. Cette méthode requiert un calcul séparé pour chaque poids dans le réseau, ce qui signifie que si nous avons un réseau avec N couches et O(n^2) connexions par couche (en supposant que chaque couche a n neurones), la complexité pour calculer la dérivée pour tous les poids serait de l'ordre de <strong>O(N * n^4)</strong> si chaque poids était calculé indépendamment.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1f5a8",
   "metadata": {},
   "source": [
    "pour chaque couche L de 1 à N: \n",
    "- Complexité: O(N), pour N couches\n",
    "    pour chaque neurone i dans la couche L: \n",
    "    - Complexité par couche: O(n), pour n neurones\n",
    "        pour chaque poids w_ij: \n",
    "        - Complexité par neurone: O(n^2), pour n poids\n",
    "            pour chaque entrée x_k: \n",
    "            - Complexité par poids: O(n), pour n entrées\n",
    "                - Calculer l'activation nécessite potentiellement O(n) opérations\n",
    "                calculer l'activation a_k \n",
    "                - Complexité par entrée: O(n)\n",
    "            fin pour\n",
    "            - Calculer la dérivée pour chaque poids indépendamment\n",
    "            calculer la dérivée de la loss par rapport à w_ij \n",
    "            - Complexité par poids: O(n)\n",
    "        fin pour\n",
    "    fin pour\n",
    "fin pour\n",
    "- Complexité totale naïve: O(Nn^4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63a10d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><strong>Approche de backpropagation :</strong>\n",
    "        <ul>\n",
    "            <li>Utilisation des dérivées des couches précédentes pour réduire la complexité globale.</li>\n",
    "            <li>Complexité du produit des dérivées par les poids pour une couche donnée : O(n<sup>2</sup>).</li>\n",
    "            <li>Complexité cumulée pour toutes les couches : O(N * n<sup>2</sup>).</li>\n",
    "            <li>Application de la dérivée pour chaque paramètre par couche : O(n), mais dominée par la complexité du produit matriciel précédent.</li>\n",
    "            <li>Complexité totale de la méthode : O(N * n<sup>2</sup>).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388c509",
   "metadata": {},
   "source": [
    "<strong>L'approche naive calcule le gradient pour chaque poids indépendamment, résultant en une complexité élevée de O(N* n^4) ). En revanche, la rétropropagation exploite des calculs réutilisables, réduisant ainsi la complexité à O(N* n^2). Cette optimisation rend l'entraînement des réseaux neuronaux profonds plus efficace et faisable.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21607a27",
   "metadata": {},
   "source": [
    "<strong>13. Quel critere doit respecter l’architecture du reseau pour permettre la backpropagation ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8a3ec",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><strong>Différentiabilité des fonctions d'activation :</strong> Chaque fonction d'activation utilisée dans le réseau doit être différentiable. La backpropagation repose sur le calcul des dérivées de la fonction de perte par rapport aux poids du réseau, ce qui nécessite la dérivée de la fonction d'activation à chaque neurone.</li>\n",
    "    <li><strong>Connexion en chaîne :</strong> Le réseau doit être composé de couches disposées de telle sorte que chaque couche reçoit uniquement des entrées de la couche précédente et envoie ses sorties uniquement à la couche suivante. Cela permet de propager l'erreur de sortie vers l'arrière de manière ordonnée.</li>\n",
    "    <li><strong>Initialisation des poids :</strong> Les poids du réseau doivent être initialisés de manière à ne pas saturer les neurones dès le début de l'apprentissage, ce qui pourrait empêcher la backpropagation de fonctionner correctement. Des techniques d'initialisation telles que l'initialisation de Xavier ou He sont souvent utilisées.</li>\n",
    "    <li><strong>Réseau alimenté vers l'avant (feedforward) :</strong> Bien que la backpropagation puisse être adaptée à certains types de réseaux récurrents, l'architecture classique pour laquelle elle a été conçue est celle d'un réseau feedforward, où les données circulent dans une seule direction, de l'entrée vers la sortie.</li>\n",
    "    <li><strong>Existence d'une fonction de perte :</strong> Une fonction de perte (ou coût) quantifiable est nécessaire pour calculer l'erreur de sortie. Cette fonction de perte doit également être différentiable pour permettre le calcul du gradient.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9e588",
   "metadata": {},
   "source": [
    "<strong>14. La fonction SoftMax et la loss de cross-entropy sont souvent utilisees ensemble et leur gradient est tres simple. Montrez que la loss se simplifie en :</strong>\n",
    "\n",
    "<img src=\"exp_loss.png\" style=\"width:500px; margin: 0 auto; display:block;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838955c8",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n",
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<p>La fonction de perte entropie croisée est définie comme:</p>\n",
    "<p>\\[\n",
    "l = -\\sum_{i} y_i \\cdot \\log(\\hat{y}_i)\n",
    "\\]</p>\n",
    "<p>Où \\( \\hat{y} \\) est la sortie du softmax, calculée comme:</p>\n",
    "<p>\\[\n",
    "\\hat{y}_i = \\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\n",
    "\\]</p>\n",
    "<p>En substituant l'expression de \\( \\hat{y}_i \\) dans l'entropie croisée, nous obtenons:</p>\n",
    "<p>\\[\n",
    "l(y, \\hat{y}) = -\\sum_{i} y_i \\cdot \\log(\\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}})\n",
    "\\]</p>\n",
    "<p>En appliquant la propriété du logarithme qui dit que \\( \\log(\\frac{a}{b}) = \\log(a) - \\log(b) \\), nous pouvons simplifier l'expression:</p>\n",
    "<p>\\[\n",
    "l(y, \\hat{y}) = -\\sum_{i} y_i \\cdot \\log(e^{x_i}) + \\log(\\sum_{j=1}^{n} e^{x_j})\n",
    "\\]</p>\n",
    "<p>En sachant que \\( \\sum_{i} y_i = 1 \\) pour une distribution de probabilité, l'expression finale est:</p>\n",
    "<p>\\[\n",
    "l = -\\sum_{i} y_i \\cdot x_i + \\log(\\sum_{j=1}^{n} e^{x_j})\n",
    "\\]</p>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ac159",
   "metadata": {},
   "source": [
    "<strong>15. Ecrire le gradient de la loss (cross-entropy) par rapport à la sortie intermediaire y^</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a16899",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n",
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<p>Pour calculer la dérivée de la fonction de perte par rapport à la sortie du softmax, nous utilisons:</p>\n",
    "<p>\\[\n",
    "\\frac{\\partial l}{\\partial \\hat{y}_i} = \\frac{\\partial}{\\partial \\hat{y}_i} \\left( -\\sum_{i} y_i \\cdot \\log(\\hat{y}_i) \\right)\n",
    "\\]</p>\n",
    "<p>Ce qui donne:</p>\n",
    "<p>\\[\n",
    "\\frac{\\partial l}{\\partial \\hat{y}_i} = -y_i + \\frac{exp(\\hat{y}_i)}{\\sum_{j} exp(\\hat{y}_j)}\n",
    "\\]</p>\n",
    "<p>Et finalement, la dérivée de l par rapport à y chapeau est:</p>\n",
    "<p>\\[\n",
    "\\frac{\\partial l}{\\partial \\hat{y}_i} = \\hat{y}_i - y_i\n",
    "\\]</p>\n",
    "<p>Le gradient de l par rapport à y est donc:</p>\n",
    "<p>\\[\n",
    "\\nabla_{\\hat{y}} l = \\left( \\frac{\\partial l}{\\partial \\hat{y}_1}, \\frac{\\partial l}{\\partial \\hat{y}_2}, \\ldots, \\frac{\\partial l}{\\partial \\hat{y}_n} \\right)\n",
    "\\]</p>\n",
    "<p>En notation vectorielle, cela s'écrit:</p>\n",
    "<p>\\[\n",
    "\\nabla_{\\hat{y}} l = (\\hat{y}_1 - y_1, \\hat{y}_2 - y_2, \\ldots, \\hat{y}_n - y_n) = \\hat{y} - y\n",
    "\\]</p>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0469c7",
   "metadata": {},
   "source": [
    "# Partie 2 – Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99cb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "## les importations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c249ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.utils.data as data \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37a04a",
   "metadata": {},
   "source": [
    "<strong><p><b>1.</b> Ecrire la fonction <code>init_params(nx, nh, ny)</code> qui initialise les poids d’un réseau à partir des tailles <code>nx</code>, <code>nh</code> et <code>ny</code> et les stocke dans un dictionnaire. Tous les poids seront initialisés selon une loi normale de moyenne 0 et d’écart-type 0.3.</p>\n",
    "<p><i>Indice</i>: utilisez les fonctions <code>torch.randn</code> et <code>torch.zeros</code>.</p></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71aa1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(nx, nh, ny):\n",
    "    \"\"\"\n",
    "    Initialise les poids d'un réseau de neurones avec des valeurs provenant d'une distribution normale\n",
    "    avec une moyenne de 0 et un écart-type de 0.3, et les stocke dans un dictionnaire.\n",
    "\n",
    "    Args:\n",
    "    nx (int): La taille de la couche d'entrée\n",
    "    nh (int): La taille de la couche cachée\n",
    "    ny (int): La taille de la couche de sortie\n",
    "\n",
    "    Returns:\n",
    "    dict: Un dictionnaire contenant les poids et biais initialisés\n",
    "    \"\"\"\n",
    "    # Initialisation des poids et des biais\n",
    "    W1 = torch.randn(nx, nh) * 0.3\n",
    "    b1 = torch.zeros(nh)\n",
    "    W2 = torch.randn(nh, ny) * 0.3\n",
    "    b2 = torch.zeros(ny)\n",
    "    \n",
    "    # Stockage dans un dictionnaire\n",
    "    params = {\n",
    "        'W1': W1,\n",
    "        'b1': b1,\n",
    "        'W2': W2,\n",
    "        'b2': b2\n",
    "    }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f202a85",
   "metadata": {},
   "source": [
    "<strong>\n",
    "<p><b>2.</b> Ecrire la fonction <code>forward(params, X)</code> qui calcule les étapes intermédiaires et la sortie du réseau \n",
    "à partir d’un batch d’entrée X de taille <code>nbatch × nx</code> et des poids stockés dans <code>params</code> et les stocke \n",
    "dans un dictionnaire. On retourne le dictionnaire des étapes intermédiaires et la sortie <code>Y_hat</code> du réseau.</p>\n",
    "<p><i>Indice</i>: on utilisera <code>torch.mm</code> pour la multiplication matricielle, et <code>torch.tanh</code>, \n",
    "<code>torch.exp</code>, <code>torch.sum</code> pour les autres opérations nécessaires.</p>\n",
    "\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a03825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, X):\n",
    "    \"\"\"\n",
    "    Calcule les étapes intermédiaires et la sortie du réseau à partir d'un batch d'entrée X.\n",
    "\n",
    "    Args:\n",
    "    params (dict): Dictionnaire contenant les poids 'W1', 'b1', 'W2', 'b2'.\n",
    "    X (torch.Tensor): Batch d'entrée de taille (nbatch, nx).\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionnaire contenant les étapes intermédiaires et la sortie Y_hat du réseau.\n",
    "    \"\"\"\n",
    "    # Extraction des poids et des biais du dictionnaire params\n",
    "    W1, b1, W2, b2 = params['W1'], params['b1'], params['W2'], params['b2']\n",
    "    \n",
    "    # Étape intermédiaire: calcul de la sortie de la première couche\n",
    "    Z1 = torch.mm(X, W1) + b1\n",
    "    A1 = torch.tanh(Z1)\n",
    "    \n",
    "    # Étape de sortie: calcul de la sortie de la deuxième couche\n",
    "    Z2 = torch.mm(A1, W2) + b2\n",
    "    Y_hat = torch.exp(Z2) / torch.sum(torch.exp(Z2), dim=1, keepdim=True)\n",
    "    \n",
    "    # Stockage des étapes intermédiaires et de la sortie dans un dictionnaire\n",
    "    forward_cache = {\n",
    "        'Z1': Z1,\n",
    "        'A1': A1,\n",
    "        'Z2': Z2,\n",
    "        'Y_hat': Y_hat\n",
    "    }\n",
    "    \n",
    "    return forward_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcebe7",
   "metadata": {},
   "source": [
    "<strong><p><b>3.</b> Ecrire la fonction <code>loss_accuracy(Y_hat, Y)</code> qui calcule la fonction de coût et la précision \n",
    "à partir d’une matrice de sortie <code>Y_hat</code> (sortie de <code>forward</code>) vis-à-vis d’une matrice de vérité \n",
    "terrain <code>Y</code> de même taille, et retourne la loss <code>L</code> et la précision <code>acc</code>.</p>\n",
    "<p>Note: On utilisera la fonction <code>_, indsY = torch.max(Y, 1)</code> qui retourne l’indice de la classe \n",
    "prédite (ou à prédire) pour chaque exemple.</p>\n",
    "<p>Indices: <code>torch.mean</code>, <code>torch.max</code>, <code>torch.log</code>, <code>torch.sum</code></p>\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "165d372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Calcule la fonction de coût (cross-entropy loss) et la précision du modèle.\n",
    "\n",
    "    Args:\n",
    "    Y_hat (torch.Tensor): Matrice des sorties prédites par le réseau (sortie de forward).\n",
    "    Y (torch.Tensor): Matrice de la vérité terrain (labels corrects).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Retourne la loss (L) et la précision (acc).\n",
    "    \"\"\"\n",
    "    # Calcul de la cross-entropy loss\n",
    "    L = -torch.mean(torch.sum(Y * torch.log(Y_hat), dim=1))\n",
    "    \n",
    "    # Calcul des indices de la classe prédite\n",
    "    _, predicted_classes = torch.max(Y_hat, 1)\n",
    "    _, true_classes = torch.max(Y, 1)\n",
    "    \n",
    "    # Calcul de la précision\n",
    "    acc = torch.mean((predicted_classes == true_classes).float())\n",
    "    \n",
    "    return L, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa830b",
   "metadata": {},
   "source": [
    "<strong>\n",
    "<p><b>4.</b> Ecrire la fonction <code>backward(params, outputs, Y)</code> qui calcule les gradients de la loss \n",
    "par rapport aux paramètres et les stocke dans un dictionnaire.</p>\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d9d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(params, outputs, Y):\n",
    "    W1, W2 = params['W1'], params['W2']\n",
    "    A1, Y_hat = outputs['A1'], outputs['Y_hat']\n",
    "\n",
    "    dZ2 = Y_hat - Y\n",
    "    dW2 = torch.mm(A1.t(), dZ2) / Y.size(0)\n",
    "    db2 = torch.sum(dZ2, dim=0) / Y.size(0)\n",
    "\n",
    "    dA1 = torch.mm(dZ2, W2.t()) * (1 - A1.pow(2))\n",
    "    dW1 = torch.mm(X_batch.t(), dA1) / Y.size(0)  # Assurez-vous que X_batch est transposé correctement\n",
    "    db1 = torch.sum(dA1, dim=0) / Y.size(0)\n",
    "\n",
    "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14129ad1",
   "metadata": {},
   "source": [
    "<strong>\n",
    "<p><b>5.</b> Ecrire la fonction <code>sgd(params, grads, eta)</code> qui applique une descente de gradient stochastique par\n",
    "mini-batch et met à jour les paramètres du réseau à partir de leurs gradients et du pas d'apprentissage.</p>\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69841d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, grads, eta):\n",
    "    \"\"\"\n",
    "    Applique une descente de gradient stochastique (SGD) pour mettre à jour les paramètres du réseau.\n",
    "\n",
    "    Args:\n",
    "    params (dict): Dictionnaire contenant les paramètres actuels du réseau 'W1', 'b1', 'W2', 'b2'.\n",
    "    grads (dict): Dictionnaire contenant les gradients de ces paramètres 'dW1', 'db1', 'dW2', 'db2'.\n",
    "    eta (float): Taux d'apprentissage.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionnaire contenant les paramètres mis à jour.\n",
    "    \"\"\"\n",
    "    # Mise à jour des paramètres avec les gradients et le taux d'apprentissage\n",
    "    params['W1'] -= eta * grads['dW1']\n",
    "    params['b1'] -= eta * grads['db1']\n",
    "    params['W2'] -= eta * grads['dW2']\n",
    "    params['b2'] -= eta * grads['db2']\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41fe5eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1: Perte = 0.7006467580795288, Précision = 40.00000059604645%\n",
      "Époque 2: Perte = 0.6560837626457214, Précision = 60.00000238418579%\n",
      "Époque 3: Perte = 0.6759769320487976, Précision = 50.0%\n",
      "Époque 4: Perte = 0.6417883634567261, Précision = 50.0%\n",
      "Époque 5: Perte = 0.6229296922683716, Précision = 60.00000238418579%\n",
      "Époque 6: Perte = 0.665391743183136, Précision = 40.00000059604645%\n",
      "Époque 7: Perte = 0.6218986511230469, Précision = 89.99999761581421%\n",
      "Époque 8: Perte = 0.6011730432510376, Précision = 89.99999761581421%\n",
      "Époque 9: Perte = 0.5769742131233215, Précision = 100.0%\n",
      "Époque 10: Perte = 0.5145117044448853, Précision = 100.0%\n",
      "Époque 11: Perte = 0.5576986074447632, Précision = 100.0%\n",
      "Époque 12: Perte = 0.525394082069397, Précision = 100.0%\n",
      "Époque 13: Perte = 0.46673744916915894, Précision = 100.0%\n",
      "Époque 14: Perte = 0.5130400657653809, Précision = 100.0%\n",
      "Époque 15: Perte = 0.47783762216567993, Précision = 100.0%\n",
      "Époque 16: Perte = 0.5126889944076538, Précision = 89.99999761581421%\n",
      "Époque 17: Perte = 0.4333222508430481, Précision = 89.99999761581421%\n",
      "Époque 18: Perte = 0.42511239647865295, Précision = 100.0%\n",
      "Époque 19: Perte = 0.41631484031677246, Précision = 100.0%\n",
      "Époque 20: Perte = 0.3681861460208893, Précision = 100.0%\n",
      "Époque 21: Perte = 0.3291562795639038, Précision = 100.0%\n",
      "Époque 22: Perte = 0.40465813875198364, Précision = 89.99999761581421%\n",
      "Époque 23: Perte = 0.3855046331882477, Précision = 100.0%\n",
      "Époque 24: Perte = 0.30879002809524536, Précision = 100.0%\n",
      "Époque 25: Perte = 0.3211345076560974, Précision = 100.0%\n",
      "Époque 26: Perte = 0.4258550703525543, Précision = 100.0%\n",
      "Époque 27: Perte = 0.315971314907074, Précision = 89.99999761581421%\n",
      "Époque 28: Perte = 0.2952978312969208, Précision = 100.0%\n",
      "Époque 29: Perte = 0.31258895993232727, Précision = 100.0%\n",
      "Époque 30: Perte = 0.23675978183746338, Précision = 100.0%\n",
      "Époque 31: Perte = 0.2399490773677826, Précision = 100.0%\n",
      "Époque 32: Perte = 0.34678417444229126, Précision = 100.0%\n",
      "Époque 33: Perte = 0.22743161022663116, Précision = 100.0%\n",
      "Époque 34: Perte = 0.2821785509586334, Précision = 100.0%\n",
      "Époque 35: Perte = 0.29653337597846985, Précision = 100.0%\n",
      "Époque 36: Perte = 0.22925427556037903, Précision = 100.0%\n",
      "Époque 37: Perte = 0.26177531480789185, Précision = 100.0%\n",
      "Époque 38: Perte = 0.22898149490356445, Précision = 100.0%\n",
      "Époque 39: Perte = 0.20109090209007263, Précision = 100.0%\n",
      "Époque 40: Perte = 0.20245185494422913, Précision = 100.0%\n",
      "Époque 41: Perte = 0.16031378507614136, Précision = 100.0%\n",
      "Époque 42: Perte = 0.13218005001544952, Précision = 100.0%\n",
      "Époque 43: Perte = 0.1709299236536026, Précision = 100.0%\n",
      "Époque 44: Perte = 0.18171045184135437, Précision = 100.0%\n",
      "Époque 45: Perte = 0.16560997068881989, Précision = 100.0%\n",
      "Époque 46: Perte = 0.09887343645095825, Précision = 100.0%\n",
      "Époque 47: Perte = 0.14097154140472412, Précision = 100.0%\n",
      "Époque 48: Perte = 0.1534375101327896, Précision = 100.0%\n",
      "Époque 49: Perte = 0.17866404354572296, Précision = 100.0%\n",
      "Époque 50: Perte = 0.24880680441856384, Précision = 89.99999761581421%\n",
      "Époque 51: Perte = 0.11324368417263031, Précision = 100.0%\n",
      "Époque 52: Perte = 0.12215179204940796, Précision = 100.0%\n",
      "Époque 53: Perte = 0.10923758894205093, Précision = 100.0%\n",
      "Époque 54: Perte = 0.10421571880578995, Précision = 100.0%\n",
      "Époque 55: Perte = 0.15279534459114075, Précision = 100.0%\n",
      "Époque 56: Perte = 0.1400890350341797, Précision = 100.0%\n",
      "Époque 57: Perte = 0.08261451870203018, Précision = 100.0%\n",
      "Époque 58: Perte = 0.1444442719221115, Précision = 100.0%\n",
      "Époque 59: Perte = 0.2144988775253296, Précision = 89.99999761581421%\n",
      "Époque 60: Perte = 0.1171058788895607, Précision = 100.0%\n",
      "Époque 61: Perte = 0.14908209443092346, Précision = 89.99999761581421%\n",
      "Époque 62: Perte = 0.12507279217243195, Précision = 100.0%\n",
      "Époque 63: Perte = 0.10157451778650284, Précision = 100.0%\n",
      "Époque 64: Perte = 0.11983169615268707, Précision = 100.0%\n",
      "Époque 65: Perte = 0.08108428865671158, Précision = 100.0%\n",
      "Époque 66: Perte = 0.12620578706264496, Précision = 100.0%\n",
      "Époque 67: Perte = 0.06222210079431534, Précision = 100.0%\n",
      "Époque 68: Perte = 0.11180869489908218, Précision = 100.0%\n",
      "Époque 69: Perte = 0.051431406289339066, Précision = 100.0%\n",
      "Époque 70: Perte = 0.1286286860704422, Précision = 100.0%\n",
      "Époque 71: Perte = 0.14476707577705383, Précision = 89.99999761581421%\n",
      "Époque 72: Perte = 0.12776386737823486, Précision = 89.99999761581421%\n",
      "Époque 73: Perte = 0.08681332319974899, Précision = 100.0%\n",
      "Époque 74: Perte = 0.10341502726078033, Précision = 100.0%\n",
      "Époque 75: Perte = 0.0918755978345871, Précision = 100.0%\n",
      "Époque 76: Perte = 0.046974435448646545, Précision = 100.0%\n",
      "Époque 77: Perte = 0.09480033814907074, Précision = 100.0%\n",
      "Époque 78: Perte = 0.1493956297636032, Précision = 100.0%\n",
      "Époque 79: Perte = 0.08104550093412399, Précision = 100.0%\n",
      "Époque 80: Perte = 0.08744765818119049, Précision = 100.0%\n",
      "Époque 81: Perte = 0.0982137992978096, Précision = 100.0%\n",
      "Époque 82: Perte = 0.10442950576543808, Précision = 100.0%\n",
      "Époque 83: Perte = 0.0841316431760788, Précision = 100.0%\n",
      "Époque 84: Perte = 0.07480625808238983, Précision = 100.0%\n",
      "Époque 85: Perte = 0.1579369157552719, Précision = 100.0%\n",
      "Époque 86: Perte = 0.07897209376096725, Précision = 100.0%\n",
      "Époque 87: Perte = 0.07732324302196503, Précision = 100.0%\n",
      "Époque 88: Perte = 0.07004565000534058, Précision = 100.0%\n",
      "Époque 89: Perte = 0.18406733870506287, Précision = 100.0%\n",
      "Époque 90: Perte = 0.084657683968544, Précision = 100.0%\n",
      "Époque 91: Perte = 0.08089668303728104, Précision = 100.0%\n",
      "Époque 92: Perte = 0.06772083044052124, Précision = 100.0%\n",
      "Époque 93: Perte = 0.03511061519384384, Précision = 100.0%\n",
      "Époque 94: Perte = 0.11748472601175308, Précision = 100.0%\n",
      "Époque 95: Perte = 0.1309460699558258, Précision = 89.99999761581421%\n",
      "Époque 96: Perte = 0.10222971439361572, Précision = 100.0%\n",
      "Époque 97: Perte = 0.12508435547351837, Précision = 89.99999761581421%\n",
      "Époque 98: Perte = 0.07794047147035599, Précision = 100.0%\n",
      "Époque 99: Perte = 0.11515508592128754, Précision = 100.0%\n",
      "Époque 100: Perte = 0.0401628240942955, Précision = 100.0%\n",
      "Époque 101: Perte = 0.07246588915586472, Précision = 100.0%\n",
      "Époque 102: Perte = 0.10914883762598038, Précision = 100.0%\n",
      "Époque 103: Perte = 0.078117236495018, Précision = 100.0%\n",
      "Époque 104: Perte = 0.07975637912750244, Précision = 100.0%\n",
      "Époque 105: Perte = 0.08698246628046036, Précision = 100.0%\n",
      "Époque 106: Perte = 0.07924880087375641, Précision = 100.0%\n",
      "Époque 107: Perte = 0.023068130016326904, Précision = 100.0%\n",
      "Époque 108: Perte = 0.10805638879537582, Précision = 100.0%\n",
      "Époque 109: Perte = 0.0818408727645874, Précision = 100.0%\n",
      "Époque 110: Perte = 0.09534643590450287, Précision = 100.0%\n",
      "Époque 111: Perte = 0.05900886654853821, Précision = 100.0%\n",
      "Époque 112: Perte = 0.10246683657169342, Précision = 100.0%\n",
      "Époque 113: Perte = 0.06724390387535095, Précision = 100.0%\n",
      "Époque 114: Perte = 0.1176581159234047, Précision = 100.0%\n",
      "Époque 115: Perte = 0.0969579666852951, Précision = 100.0%\n",
      "Époque 116: Perte = 0.08751591295003891, Précision = 100.0%\n",
      "Époque 117: Perte = 0.06790260970592499, Précision = 100.0%\n",
      "Époque 118: Perte = 0.020586732774972916, Précision = 100.0%\n",
      "Époque 119: Perte = 0.06278558075428009, Précision = 100.0%\n",
      "Époque 120: Perte = 0.05316298454999924, Précision = 100.0%\n",
      "Époque 121: Perte = 0.10752853006124496, Précision = 100.0%\n",
      "Époque 122: Perte = 0.05662459880113602, Précision = 100.0%\n",
      "Époque 123: Perte = 0.05507363751530647, Précision = 100.0%\n",
      "Époque 124: Perte = 0.02455146051943302, Précision = 100.0%\n",
      "Époque 125: Perte = 0.02553403750061989, Précision = 100.0%\n",
      "Époque 126: Perte = 0.07391557097434998, Précision = 100.0%\n",
      "Époque 127: Perte = 0.05631183832883835, Précision = 100.0%\n",
      "Époque 128: Perte = 0.06258771568536758, Précision = 100.0%\n",
      "Époque 129: Perte = 0.07561339437961578, Précision = 100.0%\n",
      "Époque 130: Perte = 0.07502175867557526, Précision = 100.0%\n",
      "Époque 131: Perte = 0.05284690111875534, Précision = 100.0%\n",
      "Époque 132: Perte = 0.0400155633687973, Précision = 100.0%\n",
      "Époque 133: Perte = 0.020774921402335167, Précision = 100.0%\n",
      "Époque 134: Perte = 0.08276735991239548, Précision = 100.0%\n",
      "Époque 135: Perte = 0.04039936885237694, Précision = 100.0%\n",
      "Époque 136: Perte = 0.083015576004982, Précision = 100.0%\n",
      "Époque 137: Perte = 0.1689472496509552, Précision = 89.99999761581421%\n",
      "Époque 138: Perte = 0.04490465298295021, Précision = 100.0%\n",
      "Époque 139: Perte = 0.027670320123434067, Précision = 100.0%\n",
      "Époque 140: Perte = 0.05944317579269409, Précision = 100.0%\n",
      "Époque 141: Perte = 0.05460459738969803, Précision = 100.0%\n",
      "Époque 142: Perte = 0.08544175326824188, Précision = 100.0%\n",
      "Époque 143: Perte = 0.04200982302427292, Précision = 100.0%\n",
      "Époque 144: Perte = 0.07327235490083694, Précision = 100.0%\n",
      "Époque 145: Perte = 0.058406174182891846, Précision = 100.0%\n",
      "Époque 146: Perte = 0.015623596496880054, Précision = 100.0%\n",
      "Époque 147: Perte = 0.1013355478644371, Précision = 100.0%\n",
      "Époque 148: Perte = 0.05862099677324295, Précision = 100.0%\n",
      "Époque 149: Perte = 0.16490726172924042, Précision = 89.99999761581421%\n",
      "Époque 150: Perte = 0.08146312087774277, Précision = 100.0%\n",
      "Époque 151: Perte = 0.023859987035393715, Précision = 100.0%\n",
      "Époque 152: Perte = 0.07361385971307755, Précision = 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 153: Perte = 0.07478148490190506, Précision = 100.0%\n",
      "Époque 154: Perte = 0.05781560018658638, Précision = 100.0%\n",
      "Époque 155: Perte = 0.0427919402718544, Précision = 100.0%\n",
      "Époque 156: Perte = 0.06873662024736404, Précision = 100.0%\n",
      "Époque 157: Perte = 0.022531315684318542, Précision = 100.0%\n",
      "Époque 158: Perte = 0.2004697024822235, Précision = 89.99999761581421%\n",
      "Époque 159: Perte = 0.1417628526687622, Précision = 89.99999761581421%\n",
      "Époque 160: Perte = 0.0750480443239212, Précision = 100.0%\n",
      "Époque 161: Perte = 0.033056098967790604, Précision = 100.0%\n",
      "Époque 162: Perte = 0.016854194924235344, Précision = 100.0%\n",
      "Époque 163: Perte = 0.16514484584331512, Précision = 89.99999761581421%\n",
      "Époque 164: Perte = 0.12724876403808594, Précision = 89.99999761581421%\n",
      "Époque 165: Perte = 0.09297565370798111, Précision = 100.0%\n",
      "Époque 166: Perte = 0.07268181443214417, Précision = 100.0%\n",
      "Époque 167: Perte = 0.03825332596898079, Précision = 100.0%\n",
      "Époque 168: Perte = 0.15203076601028442, Précision = 89.99999761581421%\n",
      "Époque 169: Perte = 0.07775119692087173, Précision = 100.0%\n",
      "Époque 170: Perte = 0.040368858724832535, Précision = 100.0%\n",
      "Époque 171: Perte = 0.06485576927661896, Précision = 100.0%\n",
      "Époque 172: Perte = 0.07620464265346527, Précision = 100.0%\n",
      "Époque 173: Perte = 0.1254884898662567, Précision = 89.99999761581421%\n",
      "Époque 174: Perte = 0.016950134187936783, Précision = 100.0%\n",
      "Époque 175: Perte = 0.036968328058719635, Précision = 100.0%\n",
      "Époque 176: Perte = 0.06025322526693344, Précision = 100.0%\n",
      "Époque 177: Perte = 0.04334874451160431, Précision = 100.0%\n",
      "Époque 178: Perte = 0.03626132383942604, Précision = 100.0%\n",
      "Époque 179: Perte = 0.06603839993476868, Précision = 100.0%\n",
      "Époque 180: Perte = 0.0440673902630806, Précision = 100.0%\n",
      "Époque 181: Perte = 0.11171732097864151, Précision = 89.99999761581421%\n",
      "Époque 182: Perte = 0.02314717322587967, Précision = 100.0%\n",
      "Époque 183: Perte = 0.010306849144399166, Précision = 100.0%\n",
      "Époque 184: Perte = 0.0816100686788559, Précision = 100.0%\n",
      "Époque 185: Perte = 0.04566404968500137, Précision = 100.0%\n",
      "Époque 186: Perte = 0.016818180680274963, Précision = 100.0%\n",
      "Époque 187: Perte = 0.04968718811869621, Précision = 100.0%\n",
      "Époque 188: Perte = 0.01920487731695175, Précision = 100.0%\n",
      "Époque 189: Perte = 0.02507442608475685, Précision = 100.0%\n",
      "Époque 190: Perte = 0.026304354891180992, Précision = 100.0%\n",
      "Époque 191: Perte = 0.010596493259072304, Précision = 100.0%\n",
      "Époque 192: Perte = 0.014347592368721962, Précision = 100.0%\n",
      "Époque 193: Perte = 0.02478867955505848, Précision = 100.0%\n",
      "Époque 194: Perte = 0.058837391436100006, Précision = 100.0%\n",
      "Époque 195: Perte = 0.018034469336271286, Précision = 100.0%\n",
      "Époque 196: Perte = 0.14010129868984222, Précision = 89.99999761581421%\n",
      "Époque 197: Perte = 0.009293792769312859, Précision = 100.0%\n",
      "Époque 198: Perte = 0.017087141051888466, Précision = 100.0%\n",
      "Époque 199: Perte = 0.03199451044201851, Précision = 100.0%\n",
      "Époque 200: Perte = 0.09033290296792984, Précision = 100.0%\n",
      "Époque 201: Perte = 0.024198001250624657, Précision = 100.0%\n",
      "Époque 202: Perte = 0.03711201250553131, Précision = 100.0%\n",
      "Époque 203: Perte = 0.027676930651068687, Précision = 100.0%\n",
      "Époque 204: Perte = 0.025727638974785805, Précision = 100.0%\n",
      "Époque 205: Perte = 0.018917154520750046, Précision = 100.0%\n",
      "Époque 206: Perte = 0.014771975576877594, Précision = 100.0%\n",
      "Époque 207: Perte = 0.04702664539217949, Précision = 100.0%\n",
      "Époque 208: Perte = 0.04876973479986191, Précision = 100.0%\n",
      "Époque 209: Perte = 0.022645387798547745, Précision = 100.0%\n",
      "Époque 210: Perte = 0.008732539601624012, Précision = 100.0%\n",
      "Époque 211: Perte = 0.15477213263511658, Précision = 89.99999761581421%\n",
      "Époque 212: Perte = 0.04037647694349289, Précision = 100.0%\n",
      "Époque 213: Perte = 0.022325213998556137, Précision = 100.0%\n",
      "Époque 214: Perte = 0.020234668627381325, Précision = 100.0%\n",
      "Époque 215: Perte = 0.024190451949834824, Précision = 100.0%\n",
      "Époque 216: Perte = 0.020847637206315994, Précision = 100.0%\n",
      "Époque 217: Perte = 0.008325603790581226, Précision = 100.0%\n",
      "Époque 218: Perte = 0.010693741030991077, Précision = 100.0%\n",
      "Époque 219: Perte = 0.028521645814180374, Précision = 100.0%\n",
      "Époque 220: Perte = 0.04480121657252312, Précision = 100.0%\n",
      "Époque 221: Perte = 0.018989991396665573, Précision = 100.0%\n",
      "Époque 222: Perte = 0.03356778621673584, Précision = 100.0%\n",
      "Époque 223: Perte = 0.018258485943078995, Précision = 100.0%\n",
      "Époque 224: Perte = 0.018334772437810898, Précision = 100.0%\n",
      "Époque 225: Perte = 0.06910963356494904, Précision = 100.0%\n",
      "Époque 226: Perte = 0.00970188993960619, Précision = 100.0%\n",
      "Époque 227: Perte = 0.06380467116832733, Précision = 100.0%\n",
      "Époque 228: Perte = 0.020586658269166946, Précision = 100.0%\n",
      "Époque 229: Perte = 0.0553707554936409, Précision = 100.0%\n",
      "Époque 230: Perte = 0.11381398141384125, Précision = 89.99999761581421%\n",
      "Époque 231: Perte = 0.06041404604911804, Précision = 100.0%\n",
      "Époque 232: Perte = 0.017811469733715057, Précision = 100.0%\n",
      "Époque 233: Perte = 0.03759917989373207, Précision = 100.0%\n",
      "Époque 234: Perte = 0.011870397254824638, Précision = 100.0%\n",
      "Époque 235: Perte = 0.05265362933278084, Précision = 100.0%\n",
      "Époque 236: Perte = 0.01696479134261608, Précision = 100.0%\n",
      "Époque 237: Perte = 0.016345392912626266, Précision = 100.0%\n",
      "Époque 238: Perte = 0.03098582662642002, Précision = 100.0%\n",
      "Époque 239: Perte = 0.030752677470445633, Précision = 100.0%\n",
      "Époque 240: Perte = 0.016009394079446793, Précision = 100.0%\n",
      "Époque 241: Perte = 0.050218693912029266, Précision = 100.0%\n",
      "Époque 242: Perte = 0.02982787787914276, Précision = 100.0%\n",
      "Époque 243: Perte = 0.030431333929300308, Précision = 100.0%\n",
      "Époque 244: Perte = 0.018984969705343246, Précision = 100.0%\n",
      "Époque 245: Perte = 0.019360456615686417, Précision = 100.0%\n",
      "Époque 246: Perte = 0.007131577935069799, Précision = 100.0%\n",
      "Époque 247: Perte = 0.04386195167899132, Précision = 100.0%\n",
      "Époque 248: Perte = 0.008335834369063377, Précision = 100.0%\n",
      "Époque 249: Perte = 0.1054551750421524, Précision = 100.0%\n",
      "Époque 250: Perte = 0.013156275264918804, Précision = 100.0%\n",
      "Époque 251: Perte = 0.05709434673190117, Précision = 100.0%\n",
      "Époque 252: Perte = 0.028999220579862595, Précision = 100.0%\n",
      "Époque 253: Perte = 0.00741307670250535, Précision = 100.0%\n",
      "Époque 254: Perte = 0.07177580893039703, Précision = 100.0%\n",
      "Époque 255: Perte = 0.03447555750608444, Précision = 100.0%\n",
      "Époque 256: Perte = 0.007572398986667395, Précision = 100.0%\n",
      "Époque 257: Perte = 0.019170334562659264, Précision = 100.0%\n",
      "Époque 258: Perte = 0.03896825388073921, Précision = 100.0%\n",
      "Époque 259: Perte = 0.011997024528682232, Précision = 100.0%\n",
      "Époque 260: Perte = 0.06474916636943817, Précision = 100.0%\n",
      "Époque 261: Perte = 0.08222858607769012, Précision = 100.0%\n",
      "Époque 262: Perte = 0.01005176268517971, Précision = 100.0%\n",
      "Époque 263: Perte = 0.01594371907413006, Précision = 100.0%\n",
      "Époque 264: Perte = 0.15992668271064758, Précision = 89.99999761581421%\n",
      "Époque 265: Perte = 0.010203027166426182, Précision = 100.0%\n",
      "Époque 266: Perte = 0.0269493218511343, Précision = 100.0%\n",
      "Époque 267: Perte = 0.05694879963994026, Précision = 100.0%\n",
      "Époque 268: Perte = 0.05115095525979996, Précision = 100.0%\n",
      "Époque 269: Perte = 0.06145026162266731, Précision = 100.0%\n",
      "Époque 270: Perte = 0.00818098895251751, Précision = 100.0%\n",
      "Époque 271: Perte = 0.027164246886968613, Précision = 100.0%\n",
      "Époque 272: Perte = 0.010448096320033073, Précision = 100.0%\n",
      "Époque 273: Perte = 0.05854130536317825, Précision = 100.0%\n",
      "Époque 274: Perte = 0.012758167460560799, Précision = 100.0%\n",
      "Époque 275: Perte = 0.05584968253970146, Précision = 100.0%\n",
      "Époque 276: Perte = 0.026048948988318443, Précision = 100.0%\n",
      "Époque 277: Perte = 0.0596136637032032, Précision = 100.0%\n",
      "Époque 278: Perte = 0.026975590735673904, Précision = 100.0%\n",
      "Époque 279: Perte = 0.03743257001042366, Précision = 100.0%\n",
      "Époque 280: Perte = 0.007163703441619873, Précision = 100.0%\n",
      "Époque 281: Perte = 0.16397564113140106, Précision = 89.99999761581421%\n",
      "Époque 282: Perte = 0.04458988457918167, Précision = 100.0%\n",
      "Époque 283: Perte = 0.019022759050130844, Précision = 100.0%\n",
      "Époque 284: Perte = 0.07238585501909256, Précision = 100.0%\n",
      "Époque 285: Perte = 0.04885812848806381, Précision = 100.0%\n",
      "Époque 286: Perte = 0.023155860602855682, Précision = 100.0%\n",
      "Époque 287: Perte = 0.03304864093661308, Précision = 100.0%\n",
      "Époque 288: Perte = 0.023502757772803307, Précision = 100.0%\n",
      "Époque 289: Perte = 0.00701181823387742, Précision = 100.0%\n",
      "Époque 290: Perte = 0.011335951276123524, Précision = 100.0%\n",
      "Époque 291: Perte = 0.08552373945713043, Précision = 100.0%\n",
      "Époque 292: Perte = 0.05122401565313339, Précision = 100.0%\n",
      "Époque 293: Perte = 0.008069493807852268, Précision = 100.0%\n",
      "Époque 294: Perte = 0.005188309587538242, Précision = 100.0%\n",
      "Époque 295: Perte = 0.006153877824544907, Précision = 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 296: Perte = 0.0803428441286087, Précision = 100.0%\n",
      "Époque 297: Perte = 0.010721296072006226, Précision = 100.0%\n",
      "Époque 298: Perte = 0.022713694721460342, Précision = 100.0%\n",
      "Époque 299: Perte = 0.026755213737487793, Précision = 100.0%\n",
      "Époque 300: Perte = 0.012509038671851158, Précision = 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paramètres de l'entraînement\n",
    "N_epoch = 300  # Nombre d'époques\n",
    "batch_size = 10  # Taille du batch\n",
    "N = 100  # Taille des données\n",
    "eta = 0.01  # Taux d'apprentissage\n",
    "\n",
    "# Génération et préparation des données\n",
    "X, Y = make_classification(n_samples=N, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "X_tensor = torch.tensor(X.T, dtype=torch.float32)  # Transposer X pour correspondre aux attentes de PyTorch\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.int64)\n",
    "Y_one_hot = F.one_hot(Y_tensor).float().t()  # One-hot encoding et transposition pour obtenir (classes, exemples)\n",
    "\n",
    "# Initialiser les paramètres du réseau\n",
    "params = init_params(2, 5, Y_one_hot.size(0))\n",
    "\n",
    "# Boucle d'entraînement\n",
    "loss_history = []\n",
    "for epoch in range(N_epoch):\n",
    "    # Mélange aléatoire des indices des données\n",
    "    permutation = torch.randperm(N)\n",
    "    X_shuffled = X_tensor[:, permutation]\n",
    "    Y_shuffled = Y_one_hot[:, permutation]\n",
    "\n",
    "    # Boucle sur les mini-batchs\n",
    "    for i in range(0, N, batch_size):\n",
    "        # Sélection des mini-batchs\n",
    "        X_batch = X_shuffled[:, i:i + batch_size].t()  # Transposition pour batch x features\n",
    "        Y_batch = Y_shuffled[:, i:i + batch_size].t()  # Transposition pour batch x classes\n",
    "\n",
    "        # Propagation avant\n",
    "        outputs = forward(params, X_batch)\n",
    "\n",
    "        # Calcul de la perte et de la précision\n",
    "        loss, acc = loss_accuracy(outputs['Y_hat'], Y_batch)\n",
    "\n",
    "        # Rétropropagation et mise à jour des paramètres\n",
    "        grads = backward(params, outputs, Y_batch)\n",
    "        params = sgd(params, grads, eta)\n",
    "\n",
    "        # Enregistrement de la perte\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # Affichage de la perte et de la précision pour chaque époque\n",
    "    print(f\"Époque {epoch + 1}: Perte = {loss.item()}, Précision = {acc.item() * 100}%\")\n",
    "\n",
    "# Affichage de la courbe de perte après l'entraînement\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.title('Évolution de la perte au fil des époques')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954bbdd",
   "metadata": {},
   "source": [
    "## 2.2 Simplification du backward avec torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dae5b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1)\n",
    "def init_params(nx, nh, ny):\n",
    "    W1 = torch.randn(nx, nh, requires_grad=True) * 0.3\n",
    "    b1 = torch.zeros(nh, requires_grad=True)\n",
    "    W2 = torch.randn(nh, ny, requires_grad=True) * 0.3\n",
    "    b2 = torch.zeros(ny, requires_grad=True)\n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0171d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1, Loss: 0.6718989610671997, Accuracy: 0.699999988079071\n",
      "Époque 2, Loss: 0.6671081781387329, Accuracy: 0.699999988079071\n",
      "Époque 3, Loss: 0.6622517704963684, Accuracy: 0.699999988079071\n",
      "Époque 4, Loss: 0.6572790145874023, Accuracy: 0.699999988079071\n",
      "Époque 5, Loss: 0.6521416902542114, Accuracy: 0.800000011920929\n",
      "Époque 6, Loss: 0.6467942595481873, Accuracy: 0.8999999761581421\n",
      "Époque 7, Loss: 0.6411935091018677, Accuracy: 0.8999999761581421\n",
      "Époque 8, Loss: 0.6352981925010681, Accuracy: 0.8999999761581421\n",
      "Époque 9, Loss: 0.6290698051452637, Accuracy: 0.8999999761581421\n",
      "Époque 10, Loss: 0.6224716901779175, Accuracy: 0.8999999761581421\n",
      "Époque 11, Loss: 0.6154701113700867, Accuracy: 0.8999999761581421\n",
      "Époque 12, Loss: 0.6080344319343567, Accuracy: 0.8999999761581421\n",
      "Époque 13, Loss: 0.6001375913619995, Accuracy: 0.8999999761581421\n",
      "Époque 14, Loss: 0.5917564630508423, Accuracy: 0.8999999761581421\n",
      "Époque 15, Loss: 0.582872748374939, Accuracy: 0.8999999761581421\n",
      "Époque 16, Loss: 0.5734734535217285, Accuracy: 0.8999999761581421\n",
      "Époque 17, Loss: 0.563551664352417, Accuracy: 0.8999999761581421\n",
      "Époque 18, Loss: 0.5531071424484253, Accuracy: 0.8999999761581421\n",
      "Époque 19, Loss: 0.5421469807624817, Accuracy: 1.0\n",
      "Époque 20, Loss: 0.53068608045578, Accuracy: 1.0\n",
      "Époque 21, Loss: 0.5187473297119141, Accuracy: 1.0\n",
      "Époque 22, Loss: 0.5063621401786804, Accuracy: 1.0\n",
      "Époque 23, Loss: 0.4935700297355652, Accuracy: 1.0\n",
      "Époque 24, Loss: 0.48041772842407227, Accuracy: 1.0\n",
      "Époque 25, Loss: 0.46695971488952637, Accuracy: 1.0\n",
      "Époque 26, Loss: 0.453256219625473, Accuracy: 1.0\n",
      "Époque 27, Loss: 0.43937230110168457, Accuracy: 1.0\n",
      "Époque 28, Loss: 0.4253765046596527, Accuracy: 1.0\n",
      "Époque 29, Loss: 0.41133904457092285, Accuracy: 1.0\n",
      "Époque 30, Loss: 0.39733028411865234, Accuracy: 1.0\n",
      "Époque 31, Loss: 0.3834186792373657, Accuracy: 1.0\n",
      "Époque 32, Loss: 0.3696698546409607, Accuracy: 1.0\n",
      "Époque 33, Loss: 0.3561445474624634, Accuracy: 1.0\n",
      "Époque 34, Loss: 0.3428979516029358, Accuracy: 1.0\n",
      "Époque 35, Loss: 0.32997843623161316, Accuracy: 1.0\n",
      "Époque 36, Loss: 0.3174275755882263, Accuracy: 1.0\n",
      "Époque 37, Loss: 0.30527910590171814, Accuracy: 1.0\n",
      "Époque 38, Loss: 0.29355961084365845, Accuracy: 1.0\n",
      "Époque 39, Loss: 0.282288521528244, Accuracy: 1.0\n",
      "Époque 40, Loss: 0.27147871255874634, Accuracy: 1.0\n",
      "Époque 41, Loss: 0.26113682985305786, Accuracy: 1.0\n",
      "Époque 42, Loss: 0.2512642443180084, Accuracy: 1.0\n",
      "Époque 43, Loss: 0.24185769259929657, Accuracy: 1.0\n",
      "Époque 44, Loss: 0.2329099178314209, Accuracy: 1.0\n",
      "Époque 45, Loss: 0.22441060841083527, Accuracy: 1.0\n",
      "Époque 46, Loss: 0.21634678542613983, Accuracy: 1.0\n",
      "Époque 47, Loss: 0.2087036371231079, Accuracy: 1.0\n",
      "Époque 48, Loss: 0.20146489143371582, Accuracy: 1.0\n",
      "Époque 49, Loss: 0.19461330771446228, Accuracy: 1.0\n",
      "Époque 50, Loss: 0.18813127279281616, Accuracy: 1.0\n",
      "Époque 51, Loss: 0.18200072646141052, Accuracy: 1.0\n",
      "Époque 52, Loss: 0.17620377242565155, Accuracy: 1.0\n",
      "Époque 53, Loss: 0.17072279751300812, Accuracy: 1.0\n",
      "Époque 54, Loss: 0.16554048657417297, Accuracy: 1.0\n",
      "Époque 55, Loss: 0.16064026951789856, Accuracy: 1.0\n",
      "Époque 56, Loss: 0.15600593388080597, Accuracy: 1.0\n",
      "Époque 57, Loss: 0.15162214636802673, Accuracy: 1.0\n",
      "Époque 58, Loss: 0.14747419953346252, Accuracy: 1.0\n",
      "Époque 59, Loss: 0.14354822039604187, Accuracy: 1.0\n",
      "Époque 60, Loss: 0.13983099162578583, Accuracy: 1.0\n",
      "Époque 61, Loss: 0.13631010055541992, Accuracy: 1.0\n",
      "Époque 62, Loss: 0.1329737901687622, Accuracy: 1.0\n",
      "Époque 63, Loss: 0.12981107831001282, Accuracy: 1.0\n",
      "Époque 64, Loss: 0.12681153416633606, Accuracy: 1.0\n",
      "Époque 65, Loss: 0.1239655464887619, Accuracy: 1.0\n",
      "Époque 66, Loss: 0.12126390635967255, Accuracy: 1.0\n",
      "Époque 67, Loss: 0.11869819462299347, Accuracy: 1.0\n",
      "Époque 68, Loss: 0.11626037210226059, Accuracy: 1.0\n",
      "Époque 69, Loss: 0.11394300311803818, Accuracy: 1.0\n",
      "Époque 70, Loss: 0.11173906177282333, Accuracy: 1.0\n",
      "Époque 71, Loss: 0.10964208841323853, Accuracy: 1.0\n",
      "Époque 72, Loss: 0.10764594376087189, Accuracy: 1.0\n",
      "Époque 73, Loss: 0.10574491322040558, Accuracy: 1.0\n",
      "Époque 74, Loss: 0.10393361002206802, Accuracy: 1.0\n",
      "Époque 75, Loss: 0.10220713913440704, Accuracy: 1.0\n",
      "Époque 76, Loss: 0.10056070238351822, Accuracy: 1.0\n",
      "Époque 77, Loss: 0.09899000823497772, Accuracy: 1.0\n",
      "Époque 78, Loss: 0.09749092161655426, Accuracy: 1.0\n",
      "Époque 79, Loss: 0.09605957567691803, Accuracy: 1.0\n",
      "Époque 80, Loss: 0.0946924015879631, Accuracy: 1.0\n",
      "Époque 81, Loss: 0.09338600933551788, Accuracy: 1.0\n",
      "Époque 82, Loss: 0.09213720262050629, Accuracy: 1.0\n",
      "Époque 83, Loss: 0.09094305336475372, Accuracy: 1.0\n",
      "Époque 84, Loss: 0.08980070799589157, Accuracy: 1.0\n",
      "Époque 85, Loss: 0.08870755136013031, Accuracy: 1.0\n",
      "Époque 86, Loss: 0.08766113221645355, Accuracy: 1.0\n",
      "Époque 87, Loss: 0.08665909618139267, Accuracy: 1.0\n",
      "Époque 88, Loss: 0.08569928258657455, Accuracy: 1.0\n",
      "Époque 89, Loss: 0.08477963507175446, Accuracy: 1.0\n",
      "Époque 90, Loss: 0.0838981568813324, Accuracy: 1.0\n",
      "Époque 91, Loss: 0.0830530971288681, Accuracy: 1.0\n",
      "Époque 92, Loss: 0.08224263787269592, Accuracy: 1.0\n",
      "Époque 93, Loss: 0.08146517723798752, Accuracy: 1.0\n",
      "Époque 94, Loss: 0.0807192400097847, Accuracy: 1.0\n",
      "Époque 95, Loss: 0.08000324666500092, Accuracy: 1.0\n",
      "Époque 96, Loss: 0.0793159231543541, Accuracy: 1.0\n",
      "Époque 97, Loss: 0.0786559209227562, Accuracy: 1.0\n",
      "Époque 98, Loss: 0.07802198827266693, Accuracy: 1.0\n",
      "Époque 99, Loss: 0.07741300761699677, Accuracy: 1.0\n",
      "Époque 100, Loss: 0.07682783901691437, Accuracy: 1.0\n",
      "Époque 101, Loss: 0.07626547664403915, Accuracy: 1.0\n",
      "Époque 102, Loss: 0.07572488486766815, Accuracy: 1.0\n",
      "Époque 103, Loss: 0.07520505040884018, Accuracy: 1.0\n",
      "Époque 104, Loss: 0.07470518350601196, Accuracy: 1.0\n",
      "Époque 105, Loss: 0.07422443479299545, Accuracy: 1.0\n",
      "Époque 106, Loss: 0.07376193255186081, Accuracy: 1.0\n",
      "Époque 107, Loss: 0.07331697642803192, Accuracy: 1.0\n",
      "Époque 108, Loss: 0.07288873195648193, Accuracy: 1.0\n",
      "Époque 109, Loss: 0.07247661054134369, Accuracy: 1.0\n",
      "Époque 110, Loss: 0.07207987457513809, Accuracy: 1.0\n",
      "Époque 111, Loss: 0.07169793546199799, Accuracy: 1.0\n",
      "Époque 112, Loss: 0.07133017480373383, Accuracy: 1.0\n",
      "Époque 113, Loss: 0.07097600400447845, Accuracy: 1.0\n",
      "Époque 114, Loss: 0.07063493132591248, Accuracy: 1.0\n",
      "Époque 115, Loss: 0.07030640542507172, Accuracy: 1.0\n",
      "Époque 116, Loss: 0.06998991966247559, Accuracy: 1.0\n",
      "Époque 117, Loss: 0.0696849673986435, Accuracy: 1.0\n",
      "Époque 118, Loss: 0.0693911761045456, Accuracy: 1.0\n",
      "Époque 119, Loss: 0.0691080391407013, Accuracy: 1.0\n",
      "Époque 120, Loss: 0.06883520632982254, Accuracy: 1.0\n",
      "Époque 121, Loss: 0.06857223808765411, Accuracy: 1.0\n",
      "Époque 122, Loss: 0.06831879168748856, Accuracy: 1.0\n",
      "Époque 123, Loss: 0.06807448714971542, Accuracy: 1.0\n",
      "Époque 124, Loss: 0.06783895194530487, Accuracy: 1.0\n",
      "Époque 125, Loss: 0.06761191785335541, Accuracy: 1.0\n",
      "Époque 126, Loss: 0.06739304214715958, Accuracy: 1.0\n",
      "Époque 127, Loss: 0.0671820119023323, Accuracy: 1.0\n",
      "Époque 128, Loss: 0.0669785588979721, Accuracy: 1.0\n",
      "Époque 129, Loss: 0.06678236275911331, Accuracy: 1.0\n",
      "Époque 130, Loss: 0.06659318506717682, Accuracy: 1.0\n",
      "Époque 131, Loss: 0.06641077995300293, Accuracy: 1.0\n",
      "Époque 132, Loss: 0.06623491644859314, Accuracy: 1.0\n",
      "Époque 133, Loss: 0.06606533378362656, Accuracy: 1.0\n",
      "Époque 134, Loss: 0.06590182334184647, Accuracy: 1.0\n",
      "Époque 135, Loss: 0.06574416905641556, Accuracy: 1.0\n",
      "Époque 136, Loss: 0.06559212505817413, Accuracy: 1.0\n",
      "Époque 137, Loss: 0.06544560194015503, Accuracy: 1.0\n",
      "Époque 138, Loss: 0.06530429422855377, Accuracy: 1.0\n",
      "Époque 139, Loss: 0.06516803801059723, Accuracy: 1.0\n",
      "Époque 140, Loss: 0.06503674387931824, Accuracy: 1.0\n",
      "Époque 141, Loss: 0.0649101510643959, Accuracy: 1.0\n",
      "Époque 142, Loss: 0.06478813290596008, Accuracy: 1.0\n",
      "Époque 143, Loss: 0.06467055529356003, Accuracy: 1.0\n",
      "Époque 144, Loss: 0.06455724686384201, Accuracy: 1.0\n",
      "Époque 145, Loss: 0.06444805860519409, Accuracy: 1.0\n",
      "Époque 146, Loss: 0.06434287130832672, Accuracy: 1.0\n",
      "Époque 147, Loss: 0.06424158811569214, Accuracy: 1.0\n",
      "Époque 148, Loss: 0.06414399296045303, Accuracy: 1.0\n",
      "Époque 149, Loss: 0.06405001133680344, Accuracy: 1.0\n",
      "Époque 150, Loss: 0.0639595314860344, Accuracy: 1.0\n",
      "Époque 151, Loss: 0.06387245655059814, Accuracy: 1.0\n",
      "Époque 152, Loss: 0.06378867477178574, Accuracy: 1.0\n",
      "Époque 153, Loss: 0.06370803713798523, Accuracy: 1.0\n",
      "Époque 154, Loss: 0.06363047659397125, Accuracy: 1.0\n",
      "Époque 155, Loss: 0.06355588883161545, Accuracy: 1.0\n",
      "Époque 156, Loss: 0.06348420679569244, Accuracy: 1.0\n",
      "Époque 157, Loss: 0.0634152963757515, Accuracy: 1.0\n",
      "Époque 158, Loss: 0.06334910541772842, Accuracy: 1.0\n",
      "Époque 159, Loss: 0.06328555196523666, Accuracy: 1.0\n",
      "Époque 160, Loss: 0.06322453916072845, Accuracy: 1.0\n",
      "Époque 161, Loss: 0.06316599249839783, Accuracy: 1.0\n",
      "Époque 162, Loss: 0.06310984492301941, Accuracy: 1.0\n",
      "Époque 163, Loss: 0.06305600702762604, Accuracy: 1.0\n",
      "Époque 164, Loss: 0.06300444155931473, Accuracy: 1.0\n",
      "Époque 165, Loss: 0.06295507401227951, Accuracy: 1.0\n",
      "Époque 166, Loss: 0.06290780007839203, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 167, Loss: 0.0628625899553299, Accuracy: 1.0\n",
      "Époque 168, Loss: 0.06281939148902893, Accuracy: 1.0\n",
      "Époque 169, Loss: 0.06277815252542496, Accuracy: 1.0\n",
      "Époque 170, Loss: 0.0627388060092926, Accuracy: 1.0\n",
      "Époque 171, Loss: 0.0627012550830841, Accuracy: 1.0\n",
      "Époque 172, Loss: 0.06266553699970245, Accuracy: 1.0\n",
      "Époque 173, Loss: 0.06263155490159988, Accuracy: 1.0\n",
      "Époque 174, Loss: 0.06259923428297043, Accuracy: 1.0\n",
      "Époque 175, Loss: 0.0625685602426529, Accuracy: 1.0\n",
      "Époque 176, Loss: 0.0625394955277443, Accuracy: 1.0\n",
      "Époque 177, Loss: 0.06251195073127747, Accuracy: 1.0\n",
      "Époque 178, Loss: 0.062485914677381516, Accuracy: 1.0\n",
      "Époque 179, Loss: 0.062461357563734055, Accuracy: 1.0\n",
      "Époque 180, Loss: 0.06243825703859329, Accuracy: 1.0\n",
      "Époque 181, Loss: 0.06241654232144356, Accuracy: 1.0\n",
      "Époque 182, Loss: 0.06239618733525276, Accuracy: 1.0\n",
      "Époque 183, Loss: 0.06237714737653732, Accuracy: 1.0\n",
      "Époque 184, Loss: 0.06235937401652336, Accuracy: 1.0\n",
      "Époque 185, Loss: 0.06234285980463028, Accuracy: 1.0\n",
      "Époque 186, Loss: 0.06232757493853569, Accuracy: 1.0\n",
      "Époque 187, Loss: 0.06231347471475601, Accuracy: 1.0\n",
      "Époque 188, Loss: 0.062300533056259155, Accuracy: 1.0\n",
      "Époque 189, Loss: 0.06228872016072273, Accuracy: 1.0\n",
      "Époque 190, Loss: 0.06227802112698555, Accuracy: 1.0\n",
      "Époque 191, Loss: 0.06226838380098343, Accuracy: 1.0\n",
      "Époque 192, Loss: 0.06225978583097458, Accuracy: 1.0\n",
      "Époque 193, Loss: 0.062252242118120193, Accuracy: 1.0\n",
      "Époque 194, Loss: 0.062245648354291916, Accuracy: 1.0\n",
      "Époque 195, Loss: 0.06224004551768303, Accuracy: 1.0\n",
      "Époque 196, Loss: 0.06223537400364876, Accuracy: 1.0\n",
      "Époque 197, Loss: 0.06223165988922119, Accuracy: 1.0\n",
      "Époque 198, Loss: 0.062228839844465256, Accuracy: 1.0\n",
      "Époque 199, Loss: 0.06222689151763916, Accuracy: 1.0\n",
      "Époque 200, Loss: 0.06222580745816231, Accuracy: 1.0\n",
      "Époque 201, Loss: 0.062225591391325, Accuracy: 1.0\n",
      "Époque 202, Loss: 0.06222613900899887, Accuracy: 1.0\n",
      "Époque 203, Loss: 0.062227554619312286, Accuracy: 1.0\n",
      "Époque 204, Loss: 0.062229692935943604, Accuracy: 1.0\n",
      "Époque 205, Loss: 0.0622326135635376, Accuracy: 1.0\n",
      "Époque 206, Loss: 0.06223631650209427, Accuracy: 1.0\n",
      "Époque 207, Loss: 0.06224071979522705, Accuracy: 1.0\n",
      "Époque 208, Loss: 0.06224583461880684, Accuracy: 1.0\n",
      "Époque 209, Loss: 0.06225167587399483, Accuracy: 1.0\n",
      "Époque 210, Loss: 0.06225819140672684, Accuracy: 1.0\n",
      "Époque 211, Loss: 0.06226533651351929, Accuracy: 1.0\n",
      "Époque 212, Loss: 0.06227315217256546, Accuracy: 1.0\n",
      "Époque 213, Loss: 0.062281589955091476, Accuracy: 1.0\n",
      "Époque 214, Loss: 0.06229070574045181, Accuracy: 1.0\n",
      "Époque 215, Loss: 0.06230037659406662, Accuracy: 1.0\n",
      "Époque 216, Loss: 0.062310703098773956, Accuracy: 1.0\n",
      "Époque 217, Loss: 0.06232156231999397, Accuracy: 1.0\n",
      "Époque 218, Loss: 0.062333010137081146, Accuracy: 1.0\n",
      "Époque 219, Loss: 0.06234502047300339, Accuracy: 1.0\n",
      "Époque 220, Loss: 0.0623575821518898, Accuracy: 1.0\n",
      "Époque 221, Loss: 0.0623706690967083, Accuracy: 1.0\n",
      "Époque 222, Loss: 0.062384266406297684, Accuracy: 1.0\n",
      "Époque 223, Loss: 0.062398411333560944, Accuracy: 1.0\n",
      "Époque 224, Loss: 0.0624130554497242, Accuracy: 1.0\n",
      "Époque 225, Loss: 0.06242819502949715, Accuracy: 1.0\n",
      "Époque 226, Loss: 0.06244378536939621, Accuracy: 1.0\n",
      "Époque 227, Loss: 0.06245989352464676, Accuracy: 1.0\n",
      "Époque 228, Loss: 0.06247643381357193, Accuracy: 1.0\n",
      "Époque 229, Loss: 0.06249343231320381, Accuracy: 1.0\n",
      "Époque 230, Loss: 0.06251086294651031, Accuracy: 1.0\n",
      "Époque 231, Loss: 0.06252872943878174, Accuracy: 1.0\n",
      "Époque 232, Loss: 0.06254702806472778, Accuracy: 1.0\n",
      "Époque 233, Loss: 0.06256575137376785, Accuracy: 1.0\n",
      "Époque 234, Loss: 0.06258489191532135, Accuracy: 1.0\n",
      "Époque 235, Loss: 0.06260446459054947, Accuracy: 1.0\n",
      "Époque 236, Loss: 0.06262437254190445, Accuracy: 1.0\n",
      "Époque 237, Loss: 0.06264469027519226, Accuracy: 1.0\n",
      "Époque 238, Loss: 0.06266538798809052, Accuracy: 1.0\n",
      "Époque 239, Loss: 0.06268642842769623, Accuracy: 1.0\n",
      "Époque 240, Loss: 0.06270784884691238, Accuracy: 1.0\n",
      "Époque 241, Loss: 0.062729611992836, Accuracy: 1.0\n",
      "Époque 242, Loss: 0.06275175511837006, Accuracy: 1.0\n",
      "Époque 243, Loss: 0.06277423352003098, Accuracy: 1.0\n",
      "Époque 244, Loss: 0.06279702484607697, Accuracy: 1.0\n",
      "Époque 245, Loss: 0.0628201812505722, Accuracy: 1.0\n",
      "Époque 246, Loss: 0.06284363567829132, Accuracy: 1.0\n",
      "Époque 247, Loss: 0.0628674104809761, Accuracy: 1.0\n",
      "Époque 248, Loss: 0.06289149075746536, Accuracy: 1.0\n",
      "Époque 249, Loss: 0.0629158765077591, Accuracy: 1.0\n",
      "Époque 250, Loss: 0.0629405528306961, Accuracy: 1.0\n",
      "Époque 251, Loss: 0.06296554952859879, Accuracy: 1.0\n",
      "Époque 252, Loss: 0.06299081444740295, Accuracy: 1.0\n",
      "Époque 253, Loss: 0.06301634758710861, Accuracy: 1.0\n",
      "Époque 254, Loss: 0.06304218620061874, Accuracy: 1.0\n",
      "Époque 255, Loss: 0.06306827813386917, Accuracy: 1.0\n",
      "Époque 256, Loss: 0.06309465318918228, Accuracy: 1.0\n",
      "Époque 257, Loss: 0.0631212443113327, Accuracy: 1.0\n",
      "Époque 258, Loss: 0.0631481260061264, Accuracy: 1.0\n",
      "Époque 259, Loss: 0.0631752461194992, Accuracy: 1.0\n",
      "Époque 260, Loss: 0.0632026344537735, Accuracy: 1.0\n",
      "Époque 261, Loss: 0.0632302463054657, Accuracy: 1.0\n",
      "Époque 262, Loss: 0.063258096575737, Accuracy: 1.0\n",
      "Époque 263, Loss: 0.06328621506690979, Accuracy: 1.0\n",
      "Époque 264, Loss: 0.0633145421743393, Accuracy: 1.0\n",
      "Époque 265, Loss: 0.0633430927991867, Accuracy: 1.0\n",
      "Époque 266, Loss: 0.06337184458971024, Accuracy: 1.0\n",
      "Époque 267, Loss: 0.06340084224939346, Accuracy: 1.0\n",
      "Époque 268, Loss: 0.06343002617359161, Accuracy: 1.0\n",
      "Époque 269, Loss: 0.06345942616462708, Accuracy: 1.0\n",
      "Époque 270, Loss: 0.06348901987075806, Accuracy: 1.0\n",
      "Époque 271, Loss: 0.06351883709430695, Accuracy: 1.0\n",
      "Époque 272, Loss: 0.06354881823062897, Accuracy: 1.0\n",
      "Époque 273, Loss: 0.0635790303349495, Accuracy: 1.0\n",
      "Époque 274, Loss: 0.06360938400030136, Accuracy: 1.0\n",
      "Époque 275, Loss: 0.06363996863365173, Accuracy: 1.0\n",
      "Époque 276, Loss: 0.06367073208093643, Accuracy: 1.0\n",
      "Époque 277, Loss: 0.06370170414447784, Accuracy: 1.0\n",
      "Époque 278, Loss: 0.06373278796672821, Accuracy: 1.0\n",
      "Époque 279, Loss: 0.06376411020755768, Accuracy: 1.0\n",
      "Époque 280, Loss: 0.0637955591082573, Accuracy: 1.0\n",
      "Époque 281, Loss: 0.06382720172405243, Accuracy: 1.0\n",
      "Époque 282, Loss: 0.0638590008020401, Accuracy: 1.0\n",
      "Époque 283, Loss: 0.0638909712433815, Accuracy: 1.0\n",
      "Époque 284, Loss: 0.06392307579517365, Accuracy: 1.0\n",
      "Époque 285, Loss: 0.06395533680915833, Accuracy: 1.0\n",
      "Époque 286, Loss: 0.06398776918649673, Accuracy: 1.0\n",
      "Époque 287, Loss: 0.06402033567428589, Accuracy: 1.0\n",
      "Époque 288, Loss: 0.06405307352542877, Accuracy: 1.0\n",
      "Époque 289, Loss: 0.0640859454870224, Accuracy: 1.0\n",
      "Époque 290, Loss: 0.06411896646022797, Accuracy: 1.0\n",
      "Époque 291, Loss: 0.06415209919214249, Accuracy: 1.0\n",
      "Époque 292, Loss: 0.06418538093566895, Accuracy: 1.0\n",
      "Époque 293, Loss: 0.06421880424022675, Accuracy: 1.0\n",
      "Époque 294, Loss: 0.06425236165523529, Accuracy: 1.0\n",
      "Époque 295, Loss: 0.06428603082895279, Accuracy: 1.0\n",
      "Époque 296, Loss: 0.06431983411312103, Accuracy: 1.0\n",
      "Époque 297, Loss: 0.06435378640890121, Accuracy: 1.0\n",
      "Époque 298, Loss: 0.06438786536455154, Accuracy: 1.0\n",
      "Époque 299, Loss: 0.06442203372716904, Accuracy: 1.0\n",
      "Époque 300, Loss: 0.06445635855197906, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "## 2)\n",
    "# Paramètres du réseau et de l'entraînement\n",
    "nx, nh, ny = 2, 5, 2  # Exemple de dimensions pour les couches\n",
    "N_epoch = 300  # Nombre d'époques\n",
    "batch_size = 10  # Taille du batch\n",
    "N = 100  # Taille des données\n",
    "eta = 0.01  # Taux d'apprentissage\n",
    "\n",
    "# Initialisation des paramètres du réseau avec requires_grad=True pour le calcul des gradients\n",
    "def init_params(nx, nh, ny):\n",
    "    W1 = torch.randn(nx, nh) * 0.3\n",
    "    W1.requires_grad_()\n",
    "    b1 = torch.zeros(nh)\n",
    "    b1.requires_grad_()\n",
    "    W2 = torch.randn(nh, ny) * 0.3\n",
    "    W2.requires_grad_()\n",
    "    b2 = torch.zeros(ny)\n",
    "    b2.requires_grad_()\n",
    "    return {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "# Génération des données de classification\n",
    "X, Y = make_classification(n_samples=N, n_features=nx, n_informative=nx, n_redundant=0, random_state=1)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "Y_one_hot = F.one_hot(Y_tensor, num_classes=ny).float()\n",
    "\n",
    "params = init_params(nx, nh, ny)\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(N_epoch):\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_tensor[i:i + batch_size]\n",
    "        Y_batch = Y_one_hot[i:i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = forward(params, X_batch)\n",
    "\n",
    "        # Calcul de la perte et de la précision\n",
    "        loss, acc = loss_accuracy(outputs['Y_hat'], Y_batch)\n",
    "\n",
    "        # Réinitialisation des gradients\n",
    "        for param in params.values():\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        with torch.no_grad():\n",
    "            for name, param in params.items():\n",
    "                if param.requires_grad:\n",
    "                    param -= eta * param.grad\n",
    "\n",
    "        # Enregistrement de la perte\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # Affichage de la perte et de la précision pour chaque époque\n",
    "    print(f\"Époque {epoch + 1}, Loss: {loss.item()}, Accuracy: {acc.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbf9dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3)\n",
    "# Assurez-vous que les gradients ont été calculés avec .backward() sur la perte avant d'exécuter ce code\n",
    "with torch.no_grad():  # Début du bloc pour désactiver le suivi des gradients\n",
    "    for name, param in params.items():\n",
    "        if param.requires_grad:\n",
    "            # Mise à jour des paramètres en utilisant les gradients\n",
    "            param -= eta * param.grad\n",
    "            # Réinitialisation des gradients après la mise à jour\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f02c4",
   "metadata": {},
   "source": [
    "# 2.3 Simplification du forward avec les couches torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5b11d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1)\n",
    "def init_model(nx, nh, ny):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(nx, nh),\n",
    "        torch.nn.ReLU(),  # Utilisez ReLU comme fonction d'activation pour la couche cachée\n",
    "        torch.nn.Linear(nh, ny),\n",
    "        torch.nn.Sigmoid()  # Sigmoid est utilisé ici, mais pour une classification multiclasse, on utilisera souvent Softmax\n",
    "    )\n",
    "    loss = torch.nn.CrossEntropyLoss()  # La perte de cross-entropy est utilisée pour les tâches de classification\n",
    "\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d687641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1: Perte = 0.6132326722145081, Précision = 0.5\n",
      "Époque 2: Perte = 0.5911848545074463, Précision = 0.5299999713897705\n",
      "Époque 3: Perte = 0.5697845220565796, Précision = 0.5799999833106995\n",
      "Époque 4: Perte = 0.5487433075904846, Précision = 0.6200000047683716\n",
      "Époque 5: Perte = 0.5282787084579468, Précision = 0.7099999785423279\n",
      "Époque 6: Perte = 0.510932445526123, Précision = 0.8100000023841858\n",
      "Époque 7: Perte = 0.49429863691329956, Précision = 0.8600000143051147\n",
      "Époque 8: Perte = 0.4780896306037903, Précision = 0.8999999761581421\n",
      "Époque 9: Perte = 0.46222251653671265, Précision = 0.9100000262260437\n",
      "Époque 10: Perte = 0.4469505846500397, Précision = 0.9399999976158142\n",
      "Époque 11: Perte = 0.4342308044433594, Précision = 0.9599999785423279\n",
      "Époque 12: Perte = 0.4221678376197815, Précision = 0.9599999785423279\n",
      "Époque 13: Perte = 0.41034775972366333, Précision = 0.9700000286102295\n",
      "Époque 14: Perte = 0.3987821340560913, Précision = 0.9800000190734863\n",
      "Époque 15: Perte = 0.38752058148384094, Précision = 0.9900000095367432\n",
      "Époque 16: Perte = 0.37653541564941406, Précision = 0.9900000095367432\n",
      "Époque 17: Perte = 0.3658781051635742, Précision = 0.9900000095367432\n",
      "Époque 18: Perte = 0.3556649684906006, Précision = 0.9900000095367432\n",
      "Époque 19: Perte = 0.34574800729751587, Précision = 1.0\n",
      "Époque 20: Perte = 0.3361204266548157, Précision = 1.0\n",
      "Époque 21: Perte = 0.32682520151138306, Précision = 1.0\n",
      "Époque 22: Perte = 0.31798258423805237, Précision = 1.0\n",
      "Époque 23: Perte = 0.3094461262226105, Précision = 1.0\n",
      "Époque 24: Perte = 0.3011845052242279, Précision = 1.0\n",
      "Époque 25: Perte = 0.29322344064712524, Précision = 1.0\n",
      "Époque 26: Perte = 0.2856222987174988, Précision = 1.0\n",
      "Époque 27: Perte = 0.27853405475616455, Précision = 1.0\n",
      "Époque 28: Perte = 0.2717156708240509, Précision = 1.0\n",
      "Époque 29: Perte = 0.26513907313346863, Précision = 1.0\n",
      "Époque 30: Perte = 0.25879624485969543, Précision = 1.0\n",
      "Époque 31: Perte = 0.25267794728279114, Précision = 1.0\n",
      "Époque 32: Perte = 0.246794655919075, Précision = 1.0\n",
      "Époque 33: Perte = 0.24111780524253845, Précision = 1.0\n",
      "Époque 34: Perte = 0.2357039749622345, Précision = 1.0\n",
      "Époque 35: Perte = 0.2304895669221878, Précision = 1.0\n",
      "Époque 36: Perte = 0.22546419501304626, Précision = 1.0\n",
      "Époque 37: Perte = 0.22062043845653534, Précision = 1.0\n",
      "Époque 38: Perte = 0.21595318615436554, Précision = 1.0\n",
      "Époque 39: Perte = 0.21145038306713104, Précision = 1.0\n",
      "Époque 40: Perte = 0.20710048079490662, Précision = 1.0\n",
      "Époque 41: Perte = 0.20285579562187195, Précision = 1.0\n",
      "Époque 42: Perte = 0.19875289499759674, Précision = 1.0\n",
      "Époque 43: Perte = 0.19478532671928406, Précision = 1.0\n",
      "Époque 44: Perte = 0.19094687700271606, Précision = 1.0\n",
      "Époque 45: Perte = 0.1872318834066391, Précision = 1.0\n",
      "Époque 46: Perte = 0.1836348921060562, Précision = 1.0\n",
      "Époque 47: Perte = 0.1801508516073227, Précision = 1.0\n",
      "Époque 48: Perte = 0.17677757143974304, Précision = 1.0\n",
      "Époque 49: Perte = 0.17350804805755615, Précision = 1.0\n",
      "Époque 50: Perte = 0.17033791542053223, Précision = 1.0\n",
      "Époque 51: Perte = 0.16726477444171906, Précision = 1.0\n",
      "Époque 52: Perte = 0.16428323090076447, Précision = 1.0\n",
      "Époque 53: Perte = 0.16139228641986847, Précision = 1.0\n",
      "Époque 54: Perte = 0.15858587622642517, Précision = 1.0\n",
      "Époque 55: Perte = 0.1558636873960495, Précision = 1.0\n",
      "Époque 56: Perte = 0.15321952104568481, Précision = 1.0\n",
      "Époque 57: Perte = 0.15065045654773712, Précision = 1.0\n",
      "Époque 58: Perte = 0.14815357327461243, Précision = 1.0\n",
      "Époque 59: Perte = 0.14572614431381226, Précision = 1.0\n",
      "Époque 60: Perte = 0.14336571097373962, Précision = 1.0\n",
      "Époque 61: Perte = 0.1410696804523468, Précision = 1.0\n",
      "Époque 62: Perte = 0.13883575797080994, Précision = 1.0\n",
      "Époque 63: Perte = 0.13666167855262756, Précision = 1.0\n",
      "Époque 64: Perte = 0.13454528152942657, Précision = 1.0\n",
      "Époque 65: Perte = 0.1324845403432846, Précision = 1.0\n",
      "Époque 66: Perte = 0.13047748804092407, Précision = 1.0\n",
      "Époque 67: Perte = 0.12852229177951813, Précision = 1.0\n",
      "Époque 68: Perte = 0.12661705911159515, Précision = 1.0\n",
      "Époque 69: Perte = 0.12476017326116562, Précision = 1.0\n",
      "Époque 70: Perte = 0.12294993549585342, Précision = 1.0\n",
      "Époque 71: Perte = 0.1211848109960556, Précision = 1.0\n",
      "Époque 72: Perte = 0.1194632276892662, Précision = 1.0\n",
      "Époque 73: Perte = 0.11778893321752548, Précision = 1.0\n",
      "Époque 74: Perte = 0.11613955348730087, Précision = 1.0\n",
      "Époque 75: Perte = 0.11453191190958023, Précision = 1.0\n",
      "Époque 76: Perte = 0.1129627674818039, Précision = 1.0\n",
      "Époque 77: Perte = 0.11143094301223755, Précision = 1.0\n",
      "Époque 78: Perte = 0.10993518680334091, Précision = 1.0\n",
      "Époque 79: Perte = 0.10847432911396027, Précision = 1.0\n",
      "Époque 80: Perte = 0.10704728215932846, Précision = 1.0\n",
      "Époque 81: Perte = 0.10565298795700073, Précision = 1.0\n",
      "Époque 82: Perte = 0.1042904406785965, Précision = 1.0\n",
      "Époque 83: Perte = 0.102958545088768, Précision = 1.0\n",
      "Époque 84: Perte = 0.10165651142597198, Précision = 1.0\n",
      "Époque 85: Perte = 0.10038324445486069, Précision = 1.0\n",
      "Époque 86: Perte = 0.09913802146911621, Précision = 1.0\n",
      "Époque 87: Perte = 0.09791994094848633, Précision = 1.0\n",
      "Époque 88: Perte = 0.09672854840755463, Précision = 1.0\n",
      "Époque 89: Perte = 0.09556922316551208, Précision = 1.0\n",
      "Époque 90: Perte = 0.09443464130163193, Précision = 1.0\n",
      "Époque 91: Perte = 0.09332399070262909, Précision = 1.0\n",
      "Époque 92: Perte = 0.09223669767379761, Précision = 1.0\n",
      "Époque 93: Perte = 0.09117195755243301, Précision = 1.0\n",
      "Époque 94: Perte = 0.09012917429208755, Précision = 1.0\n",
      "Époque 95: Perte = 0.0891076922416687, Précision = 1.0\n",
      "Époque 96: Perte = 0.08810697495937347, Précision = 1.0\n",
      "Époque 97: Perte = 0.08712637424468994, Précision = 1.0\n",
      "Époque 98: Perte = 0.08616538345813751, Précision = 1.0\n",
      "Époque 99: Perte = 0.08522342145442963, Précision = 1.0\n",
      "Époque 100: Perte = 0.0842999666929245, Précision = 1.0\n",
      "Époque 101: Perte = 0.08339451253414154, Précision = 1.0\n",
      "Époque 102: Perte = 0.08250654488801956, Précision = 1.0\n",
      "Époque 103: Perte = 0.0816357210278511, Précision = 1.0\n",
      "Époque 104: Perte = 0.08078140765428543, Précision = 1.0\n",
      "Époque 105: Perte = 0.07994326204061508, Précision = 1.0\n",
      "Époque 106: Perte = 0.07912085950374603, Précision = 1.0\n",
      "Époque 107: Perte = 0.0783124715089798, Précision = 1.0\n",
      "Époque 108: Perte = 0.07751904428005219, Précision = 1.0\n",
      "Époque 109: Perte = 0.07674016058444977, Précision = 1.0\n",
      "Époque 110: Perte = 0.07597552984952927, Précision = 1.0\n",
      "Époque 111: Perte = 0.07522471249103546, Précision = 1.0\n",
      "Époque 112: Perte = 0.0744873434305191, Précision = 1.0\n",
      "Époque 113: Perte = 0.07376313209533691, Précision = 1.0\n",
      "Époque 114: Perte = 0.07305170595645905, Précision = 1.0\n",
      "Époque 115: Perte = 0.07235284149646759, Précision = 1.0\n",
      "Époque 116: Perte = 0.07166609913110733, Précision = 1.0\n",
      "Époque 117: Perte = 0.07099123299121857, Précision = 1.0\n",
      "Époque 118: Perte = 0.070327989757061, Précision = 1.0\n",
      "Époque 119: Perte = 0.0696759968996048, Précision = 1.0\n",
      "Époque 120: Perte = 0.06903515756130219, Précision = 1.0\n",
      "Époque 121: Perte = 0.06840501725673676, Précision = 1.0\n",
      "Époque 122: Perte = 0.06778542697429657, Précision = 1.0\n",
      "Époque 123: Perte = 0.06717609614133835, Précision = 1.0\n",
      "Époque 124: Perte = 0.06657682359218597, Précision = 1.0\n",
      "Époque 125: Perte = 0.06598729640245438, Précision = 1.0\n",
      "Époque 126: Perte = 0.0654074102640152, Précision = 1.0\n",
      "Époque 127: Perte = 0.06483687460422516, Précision = 1.0\n",
      "Époque 128: Perte = 0.06427548825740814, Précision = 1.0\n",
      "Époque 129: Perte = 0.06372302770614624, Précision = 1.0\n",
      "Époque 130: Perte = 0.06317926943302155, Précision = 1.0\n",
      "Époque 131: Perte = 0.0626440942287445, Précision = 1.0\n",
      "Époque 132: Perte = 0.06211722642183304, Précision = 1.0\n",
      "Époque 133: Perte = 0.06159855052828789, Précision = 1.0\n",
      "Époque 134: Perte = 0.06108785793185234, Précision = 1.0\n",
      "Époque 135: Perte = 0.06058495119214058, Précision = 1.0\n",
      "Époque 136: Perte = 0.060089726001024246, Précision = 1.0\n",
      "Époque 137: Perte = 0.05960198491811752, Précision = 1.0\n",
      "Époque 138: Perte = 0.05912153050303459, Précision = 1.0\n",
      "Époque 139: Perte = 0.0586482509970665, Précision = 1.0\n",
      "Époque 140: Perte = 0.05818196013569832, Précision = 1.0\n",
      "Époque 141: Perte = 0.0577225461602211, Précision = 1.0\n",
      "Époque 142: Perte = 0.05726988986134529, Précision = 1.0\n",
      "Époque 143: Perte = 0.05682370811700821, Précision = 1.0\n",
      "Époque 144: Perte = 0.05638403818011284, Précision = 1.0\n",
      "Époque 145: Perte = 0.05595068261027336, Précision = 1.0\n",
      "Époque 146: Perte = 0.055523525923490524, Précision = 1.0\n",
      "Époque 147: Perte = 0.0551023967564106, Précision = 1.0\n",
      "Époque 148: Perte = 0.05468715354800224, Précision = 1.0\n",
      "Époque 149: Perte = 0.05427777022123337, Précision = 1.0\n",
      "Époque 150: Perte = 0.053874097764492035, Précision = 1.0\n",
      "Époque 151: Perte = 0.0534759946167469, Précision = 1.0\n",
      "Époque 152: Perte = 0.05307777598500252, Précision = 1.0\n",
      "Époque 153: Perte = 0.05268510431051254, Précision = 1.0\n",
      "Époque 154: Perte = 0.05229785293340683, Précision = 1.0\n",
      "Époque 155: Perte = 0.05191584676504135, Précision = 1.0\n",
      "Époque 156: Perte = 0.05153907090425491, Précision = 1.0\n",
      "Époque 157: Perte = 0.05116737633943558, Précision = 1.0\n",
      "Époque 158: Perte = 0.05080069229006767, Précision = 1.0\n",
      "Époque 159: Perte = 0.05043892189860344, Précision = 1.0\n",
      "Époque 160: Perte = 0.05008199065923691, Précision = 1.0\n",
      "Époque 161: Perte = 0.04972973093390465, Précision = 1.0\n",
      "Époque 162: Perte = 0.049382127821445465, Précision = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 163: Perte = 0.049039073288440704, Précision = 1.0\n",
      "Époque 164: Perte = 0.04870041459798813, Précision = 1.0\n",
      "Époque 165: Perte = 0.04836622625589371, Précision = 1.0\n",
      "Époque 166: Perte = 0.048036254942417145, Précision = 1.0\n",
      "Époque 167: Perte = 0.047710519284009933, Précision = 1.0\n",
      "Époque 168: Perte = 0.04738888889551163, Précision = 1.0\n",
      "Époque 169: Perte = 0.04707136005163193, Précision = 1.0\n",
      "Époque 170: Perte = 0.04675779119133949, Précision = 1.0\n",
      "Époque 171: Perte = 0.04644816368818283, Précision = 1.0\n",
      "Époque 172: Perte = 0.046141646802425385, Précision = 1.0\n",
      "Époque 173: Perte = 0.045838918536901474, Précision = 1.0\n",
      "Époque 174: Perte = 0.04553995653986931, Précision = 1.0\n",
      "Époque 175: Perte = 0.045244622975587845, Précision = 1.0\n",
      "Époque 176: Perte = 0.044952865689992905, Précision = 1.0\n",
      "Époque 177: Perte = 0.04466468468308449, Précision = 1.0\n",
      "Époque 178: Perte = 0.044379957020282745, Précision = 1.0\n",
      "Époque 179: Perte = 0.04409860819578171, Précision = 1.0\n",
      "Époque 180: Perte = 0.04382067173719406, Précision = 1.0\n",
      "Époque 181: Perte = 0.04354598745703697, Précision = 1.0\n",
      "Époque 182: Perte = 0.04327451065182686, Précision = 1.0\n",
      "Époque 183: Perte = 0.043006256222724915, Précision = 1.0\n",
      "Époque 184: Perte = 0.04274113103747368, Précision = 1.0\n",
      "Époque 185: Perte = 0.04247906059026718, Précision = 1.0\n",
      "Époque 186: Perte = 0.04221998155117035, Précision = 1.0\n",
      "Époque 187: Perte = 0.041963960975408554, Précision = 1.0\n",
      "Époque 188: Perte = 0.041710786521434784, Précision = 1.0\n",
      "Époque 189: Perte = 0.04146049544215202, Précision = 1.0\n",
      "Époque 190: Perte = 0.04121304303407669, Précision = 1.0\n",
      "Époque 191: Perte = 0.0409683994948864, Précision = 1.0\n",
      "Époque 192: Perte = 0.04072640463709831, Précision = 1.0\n",
      "Époque 193: Perte = 0.04048719257116318, Précision = 1.0\n",
      "Époque 194: Perte = 0.04025060683488846, Précision = 1.0\n",
      "Époque 195: Perte = 0.04001663252711296, Précision = 1.0\n",
      "Époque 196: Perte = 0.03978520631790161, Précision = 1.0\n",
      "Époque 197: Perte = 0.03955632075667381, Précision = 1.0\n",
      "Époque 198: Perte = 0.03932996094226837, Précision = 1.0\n",
      "Époque 199: Perte = 0.03910595923662186, Précision = 1.0\n",
      "Époque 200: Perte = 0.03888440877199173, Précision = 1.0\n",
      "Époque 201: Perte = 0.03866525739431381, Précision = 1.0\n",
      "Époque 202: Perte = 0.03844841942191124, Précision = 1.0\n",
      "Époque 203: Perte = 0.038233812898397446, Précision = 1.0\n",
      "Époque 204: Perte = 0.03802156820893288, Précision = 1.0\n",
      "Époque 205: Perte = 0.03781146928668022, Précision = 1.0\n",
      "Époque 206: Perte = 0.037603650242090225, Précision = 1.0\n",
      "Époque 207: Perte = 0.03739792853593826, Précision = 1.0\n",
      "Époque 208: Perte = 0.037194378674030304, Précision = 1.0\n",
      "Époque 209: Perte = 0.0369928702712059, Précision = 1.0\n",
      "Époque 210: Perte = 0.03679344803094864, Précision = 1.0\n",
      "Époque 211: Perte = 0.03659604489803314, Précision = 1.0\n",
      "Époque 212: Perte = 0.0364006869494915, Précision = 1.0\n",
      "Époque 213: Perte = 0.036207329481840134, Précision = 1.0\n",
      "Époque 214: Perte = 0.0360158309340477, Précision = 1.0\n",
      "Époque 215: Perte = 0.03582635521888733, Précision = 1.0\n",
      "Époque 216: Perte = 0.03563863784074783, Précision = 1.0\n",
      "Époque 217: Perte = 0.03545287251472473, Précision = 1.0\n",
      "Époque 218: Perte = 0.03526890650391579, Précision = 1.0\n",
      "Époque 219: Perte = 0.03508680313825607, Précision = 1.0\n",
      "Époque 220: Perte = 0.03490645810961723, Précision = 1.0\n",
      "Époque 221: Perte = 0.03472784906625748, Précision = 1.0\n",
      "Époque 222: Perte = 0.03455100208520889, Précision = 1.0\n",
      "Époque 223: Perte = 0.03437582030892372, Précision = 1.0\n",
      "Époque 224: Perte = 0.03420232981443405, Précision = 1.0\n",
      "Époque 225: Perte = 0.034030575305223465, Précision = 1.0\n",
      "Époque 226: Perte = 0.03386038541793823, Précision = 1.0\n",
      "Époque 227: Perte = 0.033691853284835815, Précision = 1.0\n",
      "Époque 228: Perte = 0.03352485969662666, Précision = 1.0\n",
      "Époque 229: Perte = 0.03335953503847122, Précision = 1.0\n",
      "Époque 230: Perte = 0.03319563716650009, Précision = 1.0\n",
      "Époque 231: Perte = 0.033033400774002075, Précision = 1.0\n",
      "Époque 232: Perte = 0.03287256509065628, Précision = 1.0\n",
      "Époque 233: Perte = 0.032713256776332855, Précision = 1.0\n",
      "Époque 234: Perte = 0.03255544230341911, Précision = 1.0\n",
      "Époque 235: Perte = 0.032399047166109085, Précision = 1.0\n",
      "Époque 236: Perte = 0.03224405646324158, Précision = 1.0\n",
      "Époque 237: Perte = 0.03209053725004196, Précision = 1.0\n",
      "Époque 238: Perte = 0.03193832188844681, Précision = 1.0\n",
      "Époque 239: Perte = 0.03178758546710014, Précision = 1.0\n",
      "Époque 240: Perte = 0.03163812682032585, Précision = 1.0\n",
      "Époque 241: Perte = 0.031490035355091095, Précision = 1.0\n",
      "Époque 242: Perte = 0.0313432440161705, Précision = 1.0\n",
      "Époque 243: Perte = 0.03119778260588646, Précision = 1.0\n",
      "Époque 244: Perte = 0.03105359710752964, Précision = 1.0\n",
      "Époque 245: Perte = 0.030910681933164597, Précision = 1.0\n",
      "Époque 246: Perte = 0.030769025906920433, Précision = 1.0\n",
      "Époque 247: Perte = 0.030628588050603867, Précision = 1.0\n",
      "Époque 248: Perte = 0.0304893646389246, Précision = 1.0\n",
      "Époque 249: Perte = 0.030351415276527405, Précision = 1.0\n",
      "Époque 250: Perte = 0.030214592814445496, Précision = 1.0\n",
      "Époque 251: Perte = 0.030078977346420288, Précision = 1.0\n",
      "Époque 252: Perte = 0.02994445338845253, Précision = 1.0\n",
      "Époque 253: Perte = 0.029811149463057518, Précision = 1.0\n",
      "Époque 254: Perte = 0.029678985476493835, Précision = 1.0\n",
      "Époque 255: Perte = 0.029547875747084618, Précision = 1.0\n",
      "Époque 256: Perte = 0.029417887330055237, Précision = 1.0\n",
      "Époque 257: Perte = 0.029289022088050842, Précision = 1.0\n",
      "Époque 258: Perte = 0.029161250218749046, Précision = 1.0\n",
      "Époque 259: Perte = 0.029034486040472984, Précision = 1.0\n",
      "Époque 260: Perte = 0.02890881337225437, Précision = 1.0\n",
      "Époque 261: Perte = 0.028784211724996567, Précision = 1.0\n",
      "Époque 262: Perte = 0.02866058610379696, Précision = 1.0\n",
      "Époque 263: Perte = 0.028537949547171593, Précision = 1.0\n",
      "Époque 264: Perte = 0.028416350483894348, Précision = 1.0\n",
      "Époque 265: Perte = 0.028295770287513733, Précision = 1.0\n",
      "Époque 266: Perte = 0.028176134452223778, Précision = 1.0\n",
      "Époque 267: Perte = 0.028057480230927467, Précision = 1.0\n",
      "Époque 268: Perte = 0.02793976664543152, Précision = 1.0\n",
      "Époque 269: Perte = 0.02782300114631653, Précision = 1.0\n",
      "Époque 270: Perte = 0.027707194909453392, Précision = 1.0\n",
      "Époque 271: Perte = 0.02759229764342308, Précision = 1.0\n",
      "Époque 272: Perte = 0.027478283271193504, Précision = 1.0\n",
      "Époque 273: Perte = 0.027365226298570633, Précision = 1.0\n",
      "Époque 274: Perte = 0.027252990752458572, Précision = 1.0\n",
      "Époque 275: Perte = 0.027141649276018143, Précision = 1.0\n",
      "Époque 276: Perte = 0.02703120931982994, Précision = 1.0\n",
      "Époque 277: Perte = 0.026921650394797325, Précision = 1.0\n",
      "Époque 278: Perte = 0.026812871918082237, Précision = 1.0\n",
      "Époque 279: Perte = 0.02670496143400669, Précision = 1.0\n",
      "Époque 280: Perte = 0.026597902178764343, Précision = 1.0\n",
      "Époque 281: Perte = 0.026491668075323105, Précision = 1.0\n",
      "Époque 282: Perte = 0.026386212557554245, Précision = 1.0\n",
      "Époque 283: Perte = 0.026281630620360374, Précision = 1.0\n",
      "Époque 284: Perte = 0.026177752763032913, Précision = 1.0\n",
      "Époque 285: Perte = 0.026074707508087158, Précision = 1.0\n",
      "Époque 286: Perte = 0.025972450152039528, Précision = 1.0\n",
      "Époque 287: Perte = 0.025870943441987038, Précision = 1.0\n",
      "Époque 288: Perte = 0.025770237669348717, Précision = 1.0\n",
      "Époque 289: Perte = 0.025670239701867104, Précision = 1.0\n",
      "Époque 290: Perte = 0.025571009144186974, Précision = 1.0\n",
      "Époque 291: Perte = 0.025472497567534447, Précision = 1.0\n",
      "Époque 292: Perte = 0.02537471428513527, Précision = 1.0\n",
      "Époque 293: Perte = 0.025277668610215187, Précision = 1.0\n",
      "Époque 294: Perte = 0.025181323289871216, Précision = 1.0\n",
      "Époque 295: Perte = 0.0250856913626194, Précision = 1.0\n",
      "Époque 296: Perte = 0.02499070204794407, Précision = 1.0\n",
      "Époque 297: Perte = 0.024896467104554176, Précision = 1.0\n",
      "Époque 298: Perte = 0.02480289153754711, Précision = 1.0\n",
      "Époque 299: Perte = 0.02471001073718071, Précision = 1.0\n",
      "Époque 300: Perte = 0.024617770686745644, Précision = 1.0\n"
     ]
    }
   ],
   "source": [
    "##2)\n",
    "# Définition des dimensions du réseau\n",
    "nx, nh, ny = 2, 5, 2  # Tailles des couches d'entrée, cachée et de sortie\n",
    "N_epoch = 300  # Nombre d'époques\n",
    "batch_size = 10  # Taille du batch\n",
    "N = 100  # Nombre total de données\n",
    "eta = 0.01  # Taux d'apprentissage\n",
    "\n",
    "# Initialisation du modèle\n",
    "def init_model(nx, nh, ny):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(nx, nh),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(nh, ny)\n",
    "        # Pas de Softmax ici car CrossEntropyLoss le fait automatiquement\n",
    "    )\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()  # Fonction de perte pour la classification multiclasse\n",
    "    return model, loss_fn\n",
    "\n",
    "# Fonction de calcul de l'exactitude\n",
    "def accuracy(Y_pred, Y_true):\n",
    "    _, predicted_classes = torch.max(Y_pred, 1)\n",
    "    correct = (predicted_classes == Y_true).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()\n",
    "\n",
    "# Génération des données\n",
    "X, Y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, random_state=1)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)  # Les étiquettes doivent être de type long pour CrossEntropyLoss\n",
    "\n",
    "# Initialisation du modèle et de la fonction de perte\n",
    "model, loss_fn = init_model(nx, nh, ny)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(N_epoch):\n",
    "    for i in range(0, N, batch_size):\n",
    "        # Extraction des mini-batchs\n",
    "        X_batch = X_tensor[i:i + batch_size]\n",
    "        Y_batch = Y_tensor[i:i + batch_size]\n",
    "\n",
    "        # Calcul des prédictions\n",
    "        Y_pred = model(X_batch)\n",
    "\n",
    "        # Calcul de la perte\n",
    "        loss = loss_fn(Y_pred, Y_batch)\n",
    "\n",
    "        # Mise à zéro des gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Rétropropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= eta * param.grad\n",
    "\n",
    "        # Enregistrement de la perte pour l'affichage ultérieur\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # Calcul de l'exactitude pour l'époque\n",
    "    acc = accuracy(model(X_tensor), Y_tensor)\n",
    "\n",
    "    # Affichage de la perte et de l'exactitude\n",
    "    print(f\"Époque {epoch + 1}: Perte = {loss.item()}, Précision = {acc}\")\n",
    "\n",
    "# Notez que dans ce cas, nous n'utilisons pas d'ensemble de validation ou de test,\n",
    "# et nous n'implémentons pas de techniques telles que la validation croisée ou l'arrêt prématuré.\n",
    "# Vous devrez ajouter ces éléments pour une implémentation complète pour l'apprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "089c8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1, Loss: 0.7742823362350464, Accuracy: 0.5\n",
      "Époque 2, Loss: 0.736100435256958, Accuracy: 0.5\n",
      "Époque 3, Loss: 0.7013614773750305, Accuracy: 0.5\n",
      "Époque 4, Loss: 0.6691839694976807, Accuracy: 0.5\n",
      "Époque 5, Loss: 0.6378934383392334, Accuracy: 0.5\n",
      "Époque 6, Loss: 0.6065729260444641, Accuracy: 0.5\n",
      "Époque 7, Loss: 0.5763189196586609, Accuracy: 0.5\n",
      "Époque 8, Loss: 0.546904981136322, Accuracy: 0.5299999713897705\n",
      "Époque 9, Loss: 0.5180848836898804, Accuracy: 0.5600000023841858\n",
      "Époque 10, Loss: 0.4899293780326843, Accuracy: 0.6399999856948853\n",
      "Époque 11, Loss: 0.4623851180076599, Accuracy: 0.75\n",
      "Époque 12, Loss: 0.4355107247829437, Accuracy: 0.800000011920929\n",
      "Époque 13, Loss: 0.40936678647994995, Accuracy: 0.8399999737739563\n",
      "Époque 14, Loss: 0.38407132029533386, Accuracy: 0.9100000262260437\n",
      "Époque 15, Loss: 0.3597820997238159, Accuracy: 0.9200000166893005\n",
      "Époque 16, Loss: 0.3367820680141449, Accuracy: 0.9200000166893005\n",
      "Époque 17, Loss: 0.31501051783561707, Accuracy: 0.9399999976158142\n",
      "Époque 18, Loss: 0.29455941915512085, Accuracy: 0.9599999785423279\n",
      "Époque 19, Loss: 0.27548572421073914, Accuracy: 0.9700000286102295\n",
      "Époque 20, Loss: 0.25769203901290894, Accuracy: 0.9900000095367432\n",
      "Époque 21, Loss: 0.24114565551280975, Accuracy: 1.0\n",
      "Époque 22, Loss: 0.22581139206886292, Accuracy: 1.0\n",
      "Époque 23, Loss: 0.21162350475788116, Accuracy: 1.0\n",
      "Époque 24, Loss: 0.1985366940498352, Accuracy: 1.0\n",
      "Époque 25, Loss: 0.18646784126758575, Accuracy: 1.0\n",
      "Époque 26, Loss: 0.17535129189491272, Accuracy: 1.0\n",
      "Époque 27, Loss: 0.16512872278690338, Accuracy: 1.0\n",
      "Époque 28, Loss: 0.1557343304157257, Accuracy: 1.0\n",
      "Époque 29, Loss: 0.14713381230831146, Accuracy: 1.0\n",
      "Époque 30, Loss: 0.13920733332633972, Accuracy: 1.0\n",
      "Époque 31, Loss: 0.1319151371717453, Accuracy: 1.0\n",
      "Époque 32, Loss: 0.12519392371177673, Accuracy: 1.0\n",
      "Époque 33, Loss: 0.11897407472133636, Accuracy: 1.0\n",
      "Époque 34, Loss: 0.11321157217025757, Accuracy: 1.0\n",
      "Époque 35, Loss: 0.10786791890859604, Accuracy: 1.0\n",
      "Époque 36, Loss: 0.10291633754968643, Accuracy: 1.0\n",
      "Époque 37, Loss: 0.09831036627292633, Accuracy: 1.0\n",
      "Époque 38, Loss: 0.0940360575914383, Accuracy: 1.0\n",
      "Époque 39, Loss: 0.09004881232976913, Accuracy: 1.0\n",
      "Époque 40, Loss: 0.08632643520832062, Accuracy: 1.0\n",
      "Époque 41, Loss: 0.0828448086977005, Accuracy: 1.0\n",
      "Époque 42, Loss: 0.07958409190177917, Accuracy: 1.0\n",
      "Époque 43, Loss: 0.07653427869081497, Accuracy: 1.0\n",
      "Époque 44, Loss: 0.07367211580276489, Accuracy: 1.0\n",
      "Époque 45, Loss: 0.07098077237606049, Accuracy: 1.0\n",
      "Époque 46, Loss: 0.06844700872898102, Accuracy: 1.0\n",
      "Époque 47, Loss: 0.06605881452560425, Accuracy: 1.0\n",
      "Époque 48, Loss: 0.06380614638328552, Accuracy: 1.0\n",
      "Époque 49, Loss: 0.06167859956622124, Accuracy: 1.0\n",
      "Époque 50, Loss: 0.05966640263795853, Accuracy: 1.0\n",
      "Époque 51, Loss: 0.05776133015751839, Accuracy: 1.0\n",
      "Époque 52, Loss: 0.05596436932682991, Accuracy: 1.0\n",
      "Époque 53, Loss: 0.05425925925374031, Accuracy: 1.0\n",
      "Époque 54, Loss: 0.052639782428741455, Accuracy: 1.0\n",
      "Époque 55, Loss: 0.05110014230012894, Accuracy: 1.0\n",
      "Époque 56, Loss: 0.04963507503271103, Accuracy: 1.0\n",
      "Époque 57, Loss: 0.04823976382613182, Accuracy: 1.0\n",
      "Époque 58, Loss: 0.04691013693809509, Accuracy: 1.0\n",
      "Époque 59, Loss: 0.045641638338565826, Accuracy: 1.0\n",
      "Époque 60, Loss: 0.044434379786252975, Accuracy: 1.0\n",
      "Époque 61, Loss: 0.04328056797385216, Accuracy: 1.0\n",
      "Époque 62, Loss: 0.04217710345983505, Accuracy: 1.0\n",
      "Époque 63, Loss: 0.04112094268202782, Accuracy: 1.0\n",
      "Époque 64, Loss: 0.04011062905192375, Accuracy: 1.0\n",
      "Époque 65, Loss: 0.03914225846529007, Accuracy: 1.0\n",
      "Époque 66, Loss: 0.03821339085698128, Accuracy: 1.0\n",
      "Époque 67, Loss: 0.037321820855140686, Accuracy: 1.0\n",
      "Époque 68, Loss: 0.03646588325500488, Accuracy: 1.0\n",
      "Époque 69, Loss: 0.03564329072833061, Accuracy: 1.0\n",
      "Époque 70, Loss: 0.034852273762226105, Accuracy: 1.0\n",
      "Époque 71, Loss: 0.03409113734960556, Accuracy: 1.0\n",
      "Époque 72, Loss: 0.033358361572027206, Accuracy: 1.0\n",
      "Époque 73, Loss: 0.03265249356627464, Accuracy: 1.0\n",
      "Époque 74, Loss: 0.031972385942935944, Accuracy: 1.0\n",
      "Époque 75, Loss: 0.03131651505827904, Accuracy: 1.0\n",
      "Époque 76, Loss: 0.030683714896440506, Accuracy: 1.0\n",
      "Époque 77, Loss: 0.03007284365594387, Accuracy: 1.0\n",
      "Époque 78, Loss: 0.02948291040956974, Accuracy: 1.0\n",
      "Époque 79, Loss: 0.028912857174873352, Accuracy: 1.0\n",
      "Époque 80, Loss: 0.028361788019537926, Accuracy: 1.0\n",
      "Époque 81, Loss: 0.02782881259918213, Accuracy: 1.0\n",
      "Époque 82, Loss: 0.027314070612192154, Accuracy: 1.0\n",
      "Époque 83, Loss: 0.026815811172127724, Accuracy: 1.0\n",
      "Époque 84, Loss: 0.026333242654800415, Accuracy: 1.0\n",
      "Époque 85, Loss: 0.025865698233246803, Accuracy: 1.0\n",
      "Époque 86, Loss: 0.02541251853108406, Accuracy: 1.0\n",
      "Époque 87, Loss: 0.024974841624498367, Accuracy: 1.0\n",
      "Époque 88, Loss: 0.024555213749408722, Accuracy: 1.0\n",
      "Époque 89, Loss: 0.024155599996447563, Accuracy: 1.0\n",
      "Époque 90, Loss: 0.023767704144120216, Accuracy: 1.0\n",
      "Époque 91, Loss: 0.02339085377752781, Accuracy: 1.0\n",
      "Époque 92, Loss: 0.023024579510092735, Accuracy: 1.0\n",
      "Époque 93, Loss: 0.022668469697237015, Accuracy: 1.0\n",
      "Époque 94, Loss: 0.02232215739786625, Accuracy: 1.0\n",
      "Époque 95, Loss: 0.021985264495015144, Accuracy: 1.0\n",
      "Époque 96, Loss: 0.021657396107912064, Accuracy: 1.0\n",
      "Époque 97, Loss: 0.02133823186159134, Accuracy: 1.0\n",
      "Époque 98, Loss: 0.02102743647992611, Accuracy: 1.0\n",
      "Époque 99, Loss: 0.020724695175886154, Accuracy: 1.0\n",
      "Époque 100, Loss: 0.02042977511882782, Accuracy: 1.0\n",
      "Époque 101, Loss: 0.02014230564236641, Accuracy: 1.0\n",
      "Époque 102, Loss: 0.01986205205321312, Accuracy: 1.0\n",
      "Époque 103, Loss: 0.01958879455924034, Accuracy: 1.0\n",
      "Époque 104, Loss: 0.019322263076901436, Accuracy: 1.0\n",
      "Époque 105, Loss: 0.019062206149101257, Accuracy: 1.0\n",
      "Époque 106, Loss: 0.01880844123661518, Accuracy: 1.0\n",
      "Époque 107, Loss: 0.018560681492090225, Accuracy: 1.0\n",
      "Époque 108, Loss: 0.01831890270113945, Accuracy: 1.0\n",
      "Époque 109, Loss: 0.018082741647958755, Accuracy: 1.0\n",
      "Époque 110, Loss: 0.017852045595645905, Accuracy: 1.0\n",
      "Époque 111, Loss: 0.01762668415904045, Accuracy: 1.0\n",
      "Époque 112, Loss: 0.017406392842531204, Accuracy: 1.0\n",
      "Époque 113, Loss: 0.017191031947731972, Accuracy: 1.0\n",
      "Époque 114, Loss: 0.016980500891804695, Accuracy: 1.0\n",
      "Époque 115, Loss: 0.016774596646428108, Accuracy: 1.0\n",
      "Époque 116, Loss: 0.016573181375861168, Accuracy: 1.0\n",
      "Époque 117, Loss: 0.01637611724436283, Accuracy: 1.0\n",
      "Époque 118, Loss: 0.01618329808115959, Accuracy: 1.0\n",
      "Époque 119, Loss: 0.015994718298316002, Accuracy: 1.0\n",
      "Époque 120, Loss: 0.015810281038284302, Accuracy: 1.0\n",
      "Époque 121, Loss: 0.015629742294549942, Accuracy: 1.0\n",
      "Époque 122, Loss: 0.015452866442501545, Accuracy: 1.0\n",
      "Époque 123, Loss: 0.01527961902320385, Accuracy: 1.0\n",
      "Époque 124, Loss: 0.015109854750335217, Accuracy: 1.0\n",
      "Époque 125, Loss: 0.014943527057766914, Accuracy: 1.0\n",
      "Époque 126, Loss: 0.014780503697693348, Accuracy: 1.0\n",
      "Époque 127, Loss: 0.014620700851082802, Accuracy: 1.0\n",
      "Époque 128, Loss: 0.01446401048451662, Accuracy: 1.0\n",
      "Époque 129, Loss: 0.014310362748801708, Accuracy: 1.0\n",
      "Époque 130, Loss: 0.014159666374325752, Accuracy: 1.0\n",
      "Époque 131, Loss: 0.014011867344379425, Accuracy: 1.0\n",
      "Époque 132, Loss: 0.013866802677512169, Accuracy: 1.0\n",
      "Époque 133, Loss: 0.013724491000175476, Accuracy: 1.0\n",
      "Époque 134, Loss: 0.013584834523499012, Accuracy: 1.0\n",
      "Époque 135, Loss: 0.013447748497128487, Accuracy: 1.0\n",
      "Époque 136, Loss: 0.013313171453773975, Accuracy: 1.0\n",
      "Époque 137, Loss: 0.0131810512393713, Accuracy: 1.0\n",
      "Époque 138, Loss: 0.013051368296146393, Accuracy: 1.0\n",
      "Époque 139, Loss: 0.012924030423164368, Accuracy: 1.0\n",
      "Époque 140, Loss: 0.012798963114619255, Accuracy: 1.0\n",
      "Époque 141, Loss: 0.012676069512963295, Accuracy: 1.0\n",
      "Époque 142, Loss: 0.012555321678519249, Accuracy: 1.0\n",
      "Époque 143, Loss: 0.012436668388545513, Accuracy: 1.0\n",
      "Époque 144, Loss: 0.012320059351623058, Accuracy: 1.0\n",
      "Époque 145, Loss: 0.012205416336655617, Accuracy: 1.0\n",
      "Époque 146, Loss: 0.012092718854546547, Accuracy: 1.0\n",
      "Époque 147, Loss: 0.011981943622231483, Accuracy: 1.0\n",
      "Époque 148, Loss: 0.01187296025454998, Accuracy: 1.0\n",
      "Époque 149, Loss: 0.01176583394408226, Accuracy: 1.0\n",
      "Époque 150, Loss: 0.011660444550216198, Accuracy: 1.0\n",
      "Époque 151, Loss: 0.011556770652532578, Accuracy: 1.0\n",
      "Époque 152, Loss: 0.011454791761934757, Accuracy: 1.0\n",
      "Époque 153, Loss: 0.011354424990713596, Accuracy: 1.0\n",
      "Époque 154, Loss: 0.01125570759177208, Accuracy: 1.0\n",
      "Époque 155, Loss: 0.01115850917994976, Accuracy: 1.0\n",
      "Époque 156, Loss: 0.011062883771955967, Accuracy: 1.0\n",
      "Époque 157, Loss: 0.01096873264759779, Accuracy: 1.0\n",
      "Époque 158, Loss: 0.010876046493649483, Accuracy: 1.0\n",
      "Époque 159, Loss: 0.01078479178249836, Accuracy: 1.0\n",
      "Époque 160, Loss: 0.010694921016693115, Accuracy: 1.0\n",
      "Époque 161, Loss: 0.010606389492750168, Accuracy: 1.0\n",
      "Époque 162, Loss: 0.010519256815314293, Accuracy: 1.0\n",
      "Époque 163, Loss: 0.010433393530547619, Accuracy: 1.0\n",
      "Époque 164, Loss: 0.01034882478415966, Accuracy: 1.0\n",
      "Époque 165, Loss: 0.010265527293086052, Accuracy: 1.0\n",
      "Époque 166, Loss: 0.010183419100940228, Accuracy: 1.0\n",
      "Époque 167, Loss: 0.010102549567818642, Accuracy: 1.0\n",
      "Époque 168, Loss: 0.010022835806012154, Accuracy: 1.0\n",
      "Époque 169, Loss: 0.009944254532456398, Accuracy: 1.0\n",
      "Époque 170, Loss: 0.009866817854344845, Accuracy: 1.0\n",
      "Époque 171, Loss: 0.009790493175387383, Accuracy: 1.0\n",
      "Époque 172, Loss: 0.009715256281197071, Accuracy: 1.0\n",
      "Époque 173, Loss: 0.00964106060564518, Accuracy: 1.0\n",
      "Époque 174, Loss: 0.009567895904183388, Accuracy: 1.0\n",
      "Époque 175, Loss: 0.009495772421360016, Accuracy: 1.0\n",
      "Époque 176, Loss: 0.009424597956240177, Accuracy: 1.0\n",
      "Époque 177, Loss: 0.009354443289339542, Accuracy: 1.0\n",
      "Époque 178, Loss: 0.00928522739559412, Accuracy: 1.0\n",
      "Époque 179, Loss: 0.00921694841235876, Accuracy: 1.0\n",
      "Époque 180, Loss: 0.009149610064923763, Accuracy: 1.0\n",
      "Époque 181, Loss: 0.009083176031708717, Accuracy: 1.0\n",
      "Époque 182, Loss: 0.009017598815262318, Accuracy: 1.0\n",
      "Époque 183, Loss: 0.008952914737164974, Accuracy: 1.0\n",
      "Époque 184, Loss: 0.008889100514352322, Accuracy: 1.0\n",
      "Époque 185, Loss: 0.008826074190437794, Accuracy: 1.0\n",
      "Époque 186, Loss: 0.00876389630138874, Accuracy: 1.0\n",
      "Époque 187, Loss: 0.008702505379915237, Accuracy: 1.0\n",
      "Époque 188, Loss: 0.008641915395855904, Accuracy: 1.0\n",
      "Époque 189, Loss: 0.008582117035984993, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 190, Loss: 0.008523034863173962, Accuracy: 1.0\n",
      "Époque 191, Loss: 0.008464733138680458, Accuracy: 1.0\n",
      "Époque 192, Loss: 0.008407161571085453, Accuracy: 1.0\n",
      "Époque 193, Loss: 0.008350287564098835, Accuracy: 1.0\n",
      "Époque 194, Loss: 0.008294167928397655, Accuracy: 1.0\n",
      "Époque 195, Loss: 0.008238676004111767, Accuracy: 1.0\n",
      "Époque 196, Loss: 0.008183928206562996, Accuracy: 1.0\n",
      "Époque 197, Loss: 0.008129795081913471, Accuracy: 1.0\n",
      "Époque 198, Loss: 0.008076371625065804, Accuracy: 1.0\n",
      "Époque 199, Loss: 0.008023575879633427, Accuracy: 1.0\n",
      "Époque 200, Loss: 0.007971394807100296, Accuracy: 1.0\n",
      "Époque 201, Loss: 0.007919843308627605, Accuracy: 1.0\n",
      "Époque 202, Loss: 0.007868931628763676, Accuracy: 1.0\n",
      "Époque 203, Loss: 0.007818611338734627, Accuracy: 1.0\n",
      "Époque 204, Loss: 0.0077688731253147125, Accuracy: 1.0\n",
      "Époque 205, Loss: 0.007719729095697403, Accuracy: 1.0\n",
      "Époque 206, Loss: 0.007671210914850235, Accuracy: 1.0\n",
      "Époque 207, Loss: 0.007623252458870411, Accuracy: 1.0\n",
      "Époque 208, Loss: 0.007575863040983677, Accuracy: 1.0\n",
      "Époque 209, Loss: 0.007529033813625574, Accuracy: 1.0\n",
      "Époque 210, Loss: 0.007482727058231831, Accuracy: 1.0\n",
      "Époque 211, Loss: 0.0074368976056575775, Accuracy: 1.0\n",
      "Époque 212, Loss: 0.007391651161015034, Accuracy: 1.0\n",
      "Époque 213, Loss: 0.007346857339143753, Accuracy: 1.0\n",
      "Époque 214, Loss: 0.0073025887832045555, Accuracy: 1.0\n",
      "Époque 215, Loss: 0.007258833851665258, Accuracy: 1.0\n",
      "Époque 216, Loss: 0.007215520832687616, Accuracy: 1.0\n",
      "Époque 217, Loss: 0.007172720041126013, Accuracy: 1.0\n",
      "Époque 218, Loss: 0.007130362093448639, Accuracy: 1.0\n",
      "Époque 219, Loss: 0.007088471204042435, Accuracy: 1.0\n",
      "Époque 220, Loss: 0.007047058083117008, Accuracy: 1.0\n",
      "Époque 221, Loss: 0.007006075233221054, Accuracy: 1.0\n",
      "Époque 222, Loss: 0.006965511944144964, Accuracy: 1.0\n",
      "Époque 223, Loss: 0.006925404071807861, Accuracy: 1.0\n",
      "Époque 224, Loss: 0.006885727401822805, Accuracy: 1.0\n",
      "Époque 225, Loss: 0.006846459116786718, Accuracy: 1.0\n",
      "Époque 226, Loss: 0.00680761132389307, Accuracy: 1.0\n",
      "Époque 227, Loss: 0.006769159343093634, Accuracy: 1.0\n",
      "Époque 228, Loss: 0.006731114350259304, Accuracy: 1.0\n",
      "Époque 229, Loss: 0.006693514995276928, Accuracy: 1.0\n",
      "Époque 230, Loss: 0.006656263954937458, Accuracy: 1.0\n",
      "Époque 231, Loss: 0.0066193873062729836, Accuracy: 1.0\n",
      "Époque 232, Loss: 0.006582917179912329, Accuracy: 1.0\n",
      "Époque 233, Loss: 0.0065468112006783485, Accuracy: 1.0\n",
      "Époque 234, Loss: 0.006511088460683823, Accuracy: 1.0\n",
      "Époque 235, Loss: 0.0064757405780255795, Accuracy: 1.0\n",
      "Époque 236, Loss: 0.006440753582865, Accuracy: 1.0\n",
      "Époque 237, Loss: 0.006406093947589397, Accuracy: 1.0\n",
      "Époque 238, Loss: 0.006371797062456608, Accuracy: 1.0\n",
      "Époque 239, Loss: 0.006337801925837994, Accuracy: 1.0\n",
      "Époque 240, Loss: 0.0063041821122169495, Accuracy: 1.0\n",
      "Époque 241, Loss: 0.006270877085626125, Accuracy: 1.0\n",
      "Époque 242, Loss: 0.006237923167645931, Accuracy: 1.0\n",
      "Époque 243, Loss: 0.006205260753631592, Accuracy: 1.0\n",
      "Époque 244, Loss: 0.006172914523631334, Accuracy: 1.0\n",
      "Époque 245, Loss: 0.0061408826150000095, Accuracy: 1.0\n",
      "Époque 246, Loss: 0.006109155714511871, Accuracy: 1.0\n",
      "Époque 247, Loss: 0.006077731493860483, Accuracy: 1.0\n",
      "Époque 248, Loss: 0.006046611815690994, Accuracy: 1.0\n",
      "Époque 249, Loss: 0.006015784107148647, Accuracy: 1.0\n",
      "Époque 250, Loss: 0.005985260475426912, Accuracy: 1.0\n",
      "Époque 251, Loss: 0.005955005995929241, Accuracy: 1.0\n",
      "Époque 252, Loss: 0.005925056058913469, Accuracy: 1.0\n",
      "Époque 253, Loss: 0.005895351059734821, Accuracy: 1.0\n",
      "Époque 254, Loss: 0.005865926388651133, Accuracy: 1.0\n",
      "Époque 255, Loss: 0.005836817901581526, Accuracy: 1.0\n",
      "Époque 256, Loss: 0.005807966459542513, Accuracy: 1.0\n",
      "Époque 257, Loss: 0.005779372062534094, Accuracy: 1.0\n",
      "Époque 258, Loss: 0.005751046817749739, Accuracy: 1.0\n",
      "Époque 259, Loss: 0.005722967907786369, Accuracy: 1.0\n",
      "Époque 260, Loss: 0.0056951106525957584, Accuracy: 1.0\n",
      "Époque 261, Loss: 0.005667545832693577, Accuracy: 1.0\n",
      "Époque 262, Loss: 0.005640191957354546, Accuracy: 1.0\n",
      "Époque 263, Loss: 0.005613130517303944, Accuracy: 1.0\n",
      "Époque 264, Loss: 0.005586291663348675, Accuracy: 1.0\n",
      "Époque 265, Loss: 0.005559698678553104, Accuracy: 1.0\n",
      "Époque 266, Loss: 0.0055333273485302925, Accuracy: 1.0\n",
      "Époque 267, Loss: 0.005507214460521936, Accuracy: 1.0\n",
      "Époque 268, Loss: 0.005481288302689791, Accuracy: 1.0\n",
      "Époque 269, Loss: 0.0054555959068238735, Accuracy: 1.0\n",
      "Époque 270, Loss: 0.005430174060165882, Accuracy: 1.0\n",
      "Époque 271, Loss: 0.005404927302151918, Accuracy: 1.0\n",
      "Époque 272, Loss: 0.005379891023039818, Accuracy: 1.0\n",
      "Époque 273, Loss: 0.005355112254619598, Accuracy: 1.0\n",
      "Époque 274, Loss: 0.005330509506165981, Accuracy: 1.0\n",
      "Époque 275, Loss: 0.005306117236614227, Accuracy: 1.0\n",
      "Époque 276, Loss: 0.005281935911625624, Accuracy: 1.0\n",
      "Époque 277, Loss: 0.005257989279925823, Accuracy: 1.0\n",
      "Époque 278, Loss: 0.005234206095337868, Accuracy: 1.0\n",
      "Époque 279, Loss: 0.00521062221378088, Accuracy: 1.0\n",
      "Époque 280, Loss: 0.005187273025512695, Accuracy: 1.0\n",
      "Époque 281, Loss: 0.005164099391549826, Accuracy: 1.0\n",
      "Époque 282, Loss: 0.005141113884747028, Accuracy: 1.0\n",
      "Époque 283, Loss: 0.005118291359394789, Accuracy: 1.0\n",
      "Époque 284, Loss: 0.005095692351460457, Accuracy: 1.0\n",
      "Époque 285, Loss: 0.005073244217783213, Accuracy: 1.0\n",
      "Époque 286, Loss: 0.005051008425652981, Accuracy: 1.0\n",
      "Époque 287, Loss: 0.005028948653489351, Accuracy: 1.0\n",
      "Époque 288, Loss: 0.005007075611501932, Accuracy: 1.0\n",
      "Époque 289, Loss: 0.004985391162335873, Accuracy: 1.0\n",
      "Époque 290, Loss: 0.004963834770023823, Accuracy: 1.0\n",
      "Époque 291, Loss: 0.004942466039210558, Accuracy: 1.0\n",
      "Époque 292, Loss: 0.004921297077089548, Accuracy: 1.0\n",
      "Époque 293, Loss: 0.004900280386209488, Accuracy: 1.0\n",
      "Époque 294, Loss: 0.00487942760810256, Accuracy: 1.0\n",
      "Époque 295, Loss: 0.004858751315623522, Accuracy: 1.0\n",
      "Époque 296, Loss: 0.004838215187191963, Accuracy: 1.0\n",
      "Époque 297, Loss: 0.004817855078727007, Accuracy: 1.0\n",
      "Époque 298, Loss: 0.0047976355999708176, Accuracy: 1.0\n",
      "Époque 299, Loss: 0.0047776163555681705, Accuracy: 1.0\n",
      "Époque 300, Loss: 0.0047577014192938805, Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##3)\n",
    "# Paramètres du réseau et de l'entraînement\n",
    "nx, nh, ny = 2, 5, 2  # Tailles des couches d'entrée, cachée et de sortie\n",
    "N_epoch = 300  # Nombre d'époques\n",
    "batch_size = 10  # Taille du batch\n",
    "N = 100  # Nombre total de données\n",
    "eta = 0.01  # Taux d'apprentissage\n",
    "\n",
    "# Fonction pour initialiser le modèle\n",
    "def init_model(nx, nh, ny):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(nx, nh),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(nh, ny)\n",
    "    )\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    return model, loss_fn\n",
    "\n",
    "# Fonction SGD modifiée pour prendre le modèle en argument\n",
    "def sgd(model, eta):\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= eta * param.grad\n",
    "        model.zero_grad()\n",
    "\n",
    "# Fonction pour calculer l'exactitude\n",
    "def accuracy(Y_pred, Y_true):\n",
    "    _, predicted_classes = torch.max(Y_pred, 1)\n",
    "    correct = (predicted_classes == Y_true).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()\n",
    "\n",
    "# Génération des données\n",
    "X, Y = make_classification(n_samples=N, n_features=nx, n_informative=2, n_redundant=0, n_repeated=0, n_classes=ny, n_clusters_per_class=1, random_state=1)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "# Initialisation du modèle et de la fonction de perte\n",
    "model, loss_fn = init_model(nx, nh, ny)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "loss_history = []\n",
    "for epoch in range(N_epoch):\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_tensor[i:i + batch_size]\n",
    "        Y_batch = Y_tensor[i:i + batch_size]\n",
    "\n",
    "        # Calcul des prédictions et de la perte\n",
    "        Yhat = model(X_batch)\n",
    "        loss = loss_fn(Yhat, Y_batch)\n",
    "\n",
    "        # Réinitialisation des gradients et backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Mise à jour des paramètres\n",
    "        sgd(model, eta)\n",
    "\n",
    "        # Enregistrement de la perte\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # Calcul de l'exactitude pour l'époque\n",
    "    acc = accuracy(model(X_tensor), Y_tensor)\n",
    "\n",
    "    # Affichage de la perte et de l'exactitude\n",
    "    print(f\"Époque {epoch + 1}, Loss: {loss.item()}, Accuracy: {acc}\")\n",
    "\n",
    "# Visualisation des probabilités prédites\n",
    "x_min, x_max = X_tensor[:, 0].min() - 1, X_tensor[:, 0].max() + 1\n",
    "y_min, y_max = X_tensor[:, 1].min() - 1, X_tensor[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    Ygrid = model(grid)\n",
    "    probabilities = F.softmax(Ygrid, dim=1)\n",
    "    _, predictions = torch.max(probabilities, 1)\n",
    "    Z = predictions.reshape(xx.shape)\n",
    "\n",
    "# Affichage de la frontière de décision\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolor='k')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()\n",
    "\n",
    "# Affichage de la courbe de perte\n",
    "plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d09f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259a4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522cdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
